I"İ&<h1 id="bertå‘½åå®ä½“è¯†åˆ«tensorflow">BERTå‘½åå®ä½“è¯†åˆ«TensorFlow</h1>

<h1 id="ä¸€åŸºäºæºç å®‰è£…">ä¸€ã€åŸºäºæºç å®‰è£…</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/macanv/BERT-BiLSTM-CRF-NER
cd BERT-BiLSTM-CRF-NER/
python3 setup.py install
</code></pre></div></div>

<h1 id="äºŒä¸¤ä¸ªå‘½ä»¤è¡Œå·¥å…·bert-base-ner-train-åŸºäºå‘½åè¡Œè®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹">äºŒã€ä¸¤ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼šbert-base-ner-train åŸºäºå‘½åè¡Œè®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹</h1>

<p>å®‰è£…å®Œbert-baseåï¼Œä¼šç”Ÿæˆä¸¤ä¸ªåŸºäºå‘½åè¡Œçš„å·¥å…·ï¼Œå…¶ä¸­bert-base-ner-trainæ”¯æŒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒï¼Œä½ åªéœ€è¦æŒ‡å®šè®­ç»ƒæ•°æ®çš„ç›®å½•ï¼ŒBERTç›¸å…³å‚æ•°çš„ç›®å½•å³å¯ã€‚å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹å¸®åŠ©</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensorflow) root@e1fd7a8d1822:~/tian# bert-base-ner-train  -help
usage: bert-base-ner-train [-h] [-data_dir DATA_DIR]
                           [-bert_config_file BERT_CONFIG_FILE]
                           [-output_dir OUTPUT_DIR]
                           [-init_checkpoint INIT_CHECKPOINT]
                           [-vocab_file VOCAB_FILE]
                           [-max_seq_length MAX_SEQ_LENGTH] [-do_train]
                           [-do_eval] [-do_predict] [-batch_size BATCH_SIZE]
                           [-learning_rate LEARNING_RATE]
                           [-num_train_epochs NUM_TRAIN_EPOCHS]
                           [-dropout_rate DROPOUT_RATE] [-clip CLIP]
                           [-warmup_proportion WARMUP_PROPORTION]
                           [-lstm_size LSTM_SIZE] [-num_layers NUM_LAYERS]
                           [-cell CELL]
                           [-save_checkpoints_steps SAVE_CHECKPOINTS_STEPS]
                           [-save_summary_steps SAVE_SUMMARY_STEPS]
                           [-filter_adam_var FILTER_ADAM_VAR]
                           [-do_lower_case DO_LOWER_CASE] [-clean CLEAN]
                           [-device_map DEVICE_MAP] [-label_list LABEL_LIST]
                           [-verbose] [-ner NER] [-version]
bert-base-ner-train: error: argument -h/--help: ignored explicit argument 'elp'
</code></pre></div></div>

<p>è®­ç»ƒçš„äº‹ä¾‹å‘½åå¦‚ä¸‹ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-ner-train \
    -data_dir {your dataset dir}\
    -output_dir {training output dir}\
    -init_checkpoint {Google BERT model dir}\
    -bert_config_file {bert_config.json under the Google BERT model dir} \
    -vocab_file {vocab.txt under the Google BERT model dir}
</code></pre></div></div>

<ul>
  <li>
    <p>data_diræ˜¯ä½ çš„æ•°æ®æ‰€åœ¨çš„ç›®å½•ï¼Œè®­ç»ƒæ•°æ®ï¼ŒéªŒè¯æ•°æ®å’Œæµ‹è¯•æ•°æ®å‘½åæ ¼å¼ä¸ºï¼štrain.txt, dev.txtï¼Œtest.txt,è¯·æŒ‰ç…§è¿™ä¸ªæ ¼å¼å‘½åæ–‡ä»¶ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚<a href="https://blog.csdn.net/u010189459/article/details/38546115?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task">æ•°æ®æ ‡æ³¨ä»£ç å‚è€ƒ</a>
  è®­ç»ƒæ•°æ®çš„æ ¼å¼å¦‚ä¸‹:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  æµ· O
  é’“ O
  æ¯” O
  èµ› O
  åœ° O
  ç‚¹ O
  åœ¨ O
  å¦ B-LOC
  é—¨ I-LOC
  ä¸ O
  é‡‘ B-LOC
  é—¨ I-LOC
  ä¹‹ O
  é—´ O
  çš„ O
  æµ· O
  åŸŸ O
  ã€‚ O
</code></pre></div>    </div>

    <p>æ¯è¡Œå¾—ç¬¬ä¸€ä¸ªæ˜¯å­—ï¼Œç¬¬äºŒä¸ªæ˜¯å®ƒçš„æ ‡ç­¾ï¼Œä½¿ç”¨ç©ºæ ¼â€™ â€˜åˆ†éš”ï¼Œè¯·ä¸€å®šè¦ä½¿ç”¨ç©ºæ ¼ã€‚å¥ä¸å¥ä¹‹é—´ä½¿ç”¨ç©ºè¡Œåˆ’åˆ†ã€‚ç¨‹åºä¼šè‡ªåŠ¨è¯»å–ä½ çš„æ•°æ®ã€‚</p>
  </li>
  <li>
    <p>output_dirï¼š è®­ç»ƒæ¨¡å‹è¾“å‡ºçš„æ–‡ä»¶è·¯å¾„ï¼Œæ¨¡å‹çš„checkpointä»¥åŠä¸€äº›æ ‡ç­¾æ˜ å°„è¡¨éƒ½ä¼šå­˜å‚¨åœ¨è¿™é‡Œï¼Œè¿™ä¸ªè·¯å¾„åœ¨ä½œä¸ºæœåŠ¡çš„æ—¶å€™ï¼Œå¯ä»¥æŒ‡å®šä¸º-ner_model_dir</p>
  </li>
  <li>
    <p>init_checkpoint: ä¸‹è½½çš„è°·æ­ŒBERTæ¨¡å‹</p>
  </li>
  <li>
    <p>bert_config_file ï¼š è°·æ­ŒBERTæ¨¡å‹ä¸‹é¢çš„bert_config.json</p>
  </li>
  <li>
    <p>vocab_fileï¼š è°·æ­ŒBERTæ¨¡å‹ä¸‹é¢çš„vocab.txt</p>

    <p>è®­ç»ƒå®Œæˆåï¼Œä½ å¯ä»¥åœ¨ä½ æŒ‡å®šçš„output_dirä¸­æŸ¥çœ‹è®­ç»ƒç»“æœã€‚</p>
  </li>
</ul>

<h1 id="ä¸‰bert-base-serving-start-å°†å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡è¿›è¡ŒæœåŠ¡éƒ¨ç½²">ä¸‰ã€bert-base-serving-start å°†å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡è¿›è¡ŒæœåŠ¡éƒ¨ç½²</h1>

<p>å…ˆä½¿ç”¨-helpæŸ¥çœ‹ç›¸å…³å¸®åŠ©</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensorflow) root@e1fd7a8d1822:~/tian# bert-base-serving-start -help
usage: bert-base-serving-start [-h] -bert_model_dir BERT_MODEL_DIR -model_dir
                               MODEL_DIR [-model_pb_dir MODEL_PB_DIR]
                               [-tuned_model_dir TUNED_MODEL_DIR]
                               [-ckpt_name CKPT_NAME]
                               [-config_name CONFIG_NAME]
                               [-max_seq_len MAX_SEQ_LEN]
                               [-pooling_layer POOLING_LAYER [POOLING_LAYER ...]]
                               [-pooling_strategy {NONE,REDUCE_MAX,REDUCE_MEAN,REDUCE_MEAN_MAX,FIRST_TOKEN,LAST_TOKEN}]
                               [-mask_cls_sep] [-lstm_size LSTM_SIZE]
                               [-port PORT] [-port_out PORT_OUT]
                               [-http_port HTTP_PORT]
                               [-http_max_connect HTTP_MAX_CONNECT]
                               [-cors CORS] [-num_worker NUM_WORKER]
                               [-max_batch_size MAX_BATCH_SIZE]
                               [-priority_batch_size PRIORITY_BATCH_SIZE]
                               [-cpu] [-xla] [-fp16]
                               [-gpu_memory_fraction GPU_MEMORY_FRACTION]
                               [-device_map DEVICE_MAP [DEVICE_MAP ...]]
                               [-prefetch_size PREFETCH_SIZE] [-verbose]
                               [-mode MODE] [-version]
bert-base-serving-start: error: argument -h/--help: ignored explicit argument 'elp'
</code></pre></div></div>

<p>ä½œä¸ºå‘½åå®ä½“è¯†åˆ«ä»»åŠ¡çš„æœåŠ¡ï¼Œè¿™ä¸¤ä¸ªç›®å½•æ˜¯ä½ å¿…é¡»æŒ‡å®šçš„ï¼šner_model_dir, bert_model_dir
ç„¶åä½ å°±å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤å¯åŠ¨äº†ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-serving-start \
    -model_dir C:\workspace\python\BERT_Base\output\ner2 \
    -bert_model_dir F:\chinese_L-12_H-768_A-12
    -mode NER
</code></pre></div></div>

<ul>
  <li>bert_model_dir: è°·æ­ŒBERTæ¨¡å‹çš„è§£å‹è·¯å¾„,å¯ä»¥åœ¨è¿™é‡Œä¸‹è½½ https://github.com/google-research/bert</li>
  <li>model_dir: è®­ç»ƒå¥½çš„NERæ¨¡å‹æˆ–è€…æ–‡æœ¬åˆ†ç±»æ¨¡å‹çš„è·¯å¾„ï¼Œå¯¹äºä¸Šé¢çš„output_dir</li>
  <li>model_pd_dir: è¿è¡Œæ¨¡å‹ä¼˜åŒ–ä»£ç åï¼Œ ç»è¿‡æ¨¡å‹å‹ç¼©åçš„å­˜å‚¨è·¯å¾„ï¼Œä¾‹å¦‚è¿è¡Œä¸Šé¢çš„å‘½ä»¤åæ”¹è·¯å¾„ä¸‹ä¼šäº§ç”Ÿ ner_model.pb è¿™ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶</li>
  <li>mode:NER æˆ–è€…æ˜¯BERTè¿™ä¸¤ä¸ªæ¨¡å¼ï¼Œç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ˜¯NER,é‚£ä¹ˆå°±ä¼šå¯åŠ¨NERçš„æœåŠ¡ï¼Œå¦‚æœæ˜¯BERTï¼Œé‚£ä¹ˆå…·ä½“å‚æ•°å°†å’Œ[bert as service] é¡¹ç›®ä¸­å¾—ä¸€æ ·ã€‚</li>
</ul>

<h1 id="å››åœ¨æœ¬åœ°è¿æ¥æœåŠ¡ç«¯è¿›è¡Œå‘½åå®ä½“è¯†åˆ«çš„æµ‹è¯•">å››ã€åœ¨æœ¬åœ°è¿æ¥æœåŠ¡ç«¯è¿›è¡Œå‘½åå®ä½“è¯†åˆ«çš„æµ‹è¯•</h1>

<p>â€¦â€¦</p>

<h1 id="äº”è‡ªå·±è®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹">äº”ã€è‡ªå·±è®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹</h1>

<h2 id="1-ä¸‹è½½google-bert-é¢„è®­ç»ƒæ¨¡å‹">1. ä¸‹è½½Google BERT é¢„è®­ç»ƒæ¨¡å‹ï¼š</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip  
unzip chinese_L-12_H-768_A-12.zip
</code></pre></div></div>

<h2 id="2-è®­ç»ƒæ¨¡å‹">2. è®­ç»ƒæ¨¡å‹</h2>

<p>è®­ç»ƒä¹‹å‰å…ˆåœ¨é¡¹ç›®ç›®å½•ä¸­æ–°å»ºä¸€ä¸ªoutputæ–‡ä»¶å¤¹ï¼Œæ¨¡å‹çš„è¾“å‡ºï¼Œå’Œç»“æ„éƒ½ä¼šä¿å­˜åœ¨è¿™ä¸ªç›®å½•ä¸­<code class="language-plaintext highlighter-rouge">mkdir output</code></p>

<p>237ä¸Šè®­ç»ƒçš„å‘½ä»¤ï¼ˆGPUï¼‰</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-ner-train \
	-data_dir /root/tian/BERT-BiLSTM-CRF-NER/data/ne_WIPO_NER \
    -output_dir /root/tian/BERT-BiLSTM-CRF-NER/output/ne_WIPO_NER \
    -init_checkpoint /root/tian/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_model.ckpt \
    -bert_config_file /root/tian/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_config.json \
    -vocab_file /root/tian/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/vocab.txt \
    -save_summary_steps 20 \
    -batch_size 32 \
    -device_map 0
</code></pre></div></div>

<p>238ä¸Šè®­ç»ƒçš„å‘½ä»¤ï¼ˆCPUï¼‰</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-ner-train \
	-data_dir /root/tian/bert/BERT-BiLSTM-CRF-NER/data/ne_WIPO_NER \
    -output_dir /root/tian/bert/BERT-BiLSTM-CRF-NER/output/ne_WIPO_NER \
    -init_checkpoint /root/tian/bert/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_model.ckpt \
    -bert_config_file /root/tian/bert/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_config.json \
    -vocab_file /root/tian/bert/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/vocab.txt \
    -save_summary_steps 20
</code></pre></div></div>

<h1 id="links">Links:</h1>

<ol>
  <li>ã€æ–°å…¨ã€‘2019 NLP(è‡ªç„¶è¯­è¨€å¤„ç†)ä¹‹Bertè¯¾ç¨‹https://www.bilibili.com/video/av76791626?p=29</li>
  <li>åŸºäºBERTé¢„è®­ç»ƒçš„ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«TensorFlowå®ç°åšå®¢ï¼Œä¸»è¦å‚è€ƒçš„æ˜¯è¿™ç¯‡åšå®¢ï¼Œè¿˜æœ‰GitHubåº“ https://blog.csdn.net/macanv/article/details/85684284    https://github.com/macanv/BERT-BiLSTM-CRF-NER      ï¼ˆæ ¹æ®è¿™ç¯‡åšå®¢é‡Œè®­ç»ƒå®Œäº†æ¨¡å‹åå°±å¯ä»¥è¿›è¡Œé¢„æµ‹äº†ã€‚python3 terminal_predict.pyï¼‰</li>
  <li>Bert-BiLSTM-CRF-pytorch ä¸€ä¸ªGitHubåº“ï¼Œçœ‹èµ·æ¥ä¹Ÿä¸é”™ https://github.com/chenxiaoyouyou/Bert-BiLSTM-CRF-pytorch</li>
</ol>
:ET