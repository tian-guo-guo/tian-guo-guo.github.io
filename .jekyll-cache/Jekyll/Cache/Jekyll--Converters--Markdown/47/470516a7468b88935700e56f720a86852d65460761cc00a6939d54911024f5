I"Fİ<h1 id="a-survey-of-domain-adaptation-for-neural-machine-translation">A Survey of Domain Adaptation for Neural Machine Translation</h1>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716145257.png" alt="image-20200716144454719" /></p>

<h1 id="abstract">Abstract</h1>

<p>â€‹		ç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNeural MachineTranslationï¼ŒNMTï¼‰æ˜¯ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æœºå™¨ç¿»è¯‘æ–¹æ³•ï¼Œåœ¨å¤§è§„æ¨¡å¹¶è¡Œè¯­æ–™åº“çš„æƒ…å†µä¸‹ï¼Œå®ƒèƒ½æä¾›æœ€å…ˆè¿›çš„ç¿»è¯‘æ€§èƒ½ã€‚ å°½ç®¡é«˜è´¨é‡çš„é¢†åŸŸè§„èŒƒç¿»è¯‘åœ¨ç°å®ä¸–ç•Œä¸­è‡³å…³é‡è¦ï¼Œä½†é¢†åŸŸè§„èŒƒè¯­æ–™åº“é€šå¸¸ç¨€ç¼ºæˆ–æ ¹æœ¬ä¸å­˜åœ¨ï¼Œå› æ­¤æ™®é€šNMTåœ¨è¿™ç§æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ã€‚ <strong>åŸŸè‡ªé€‚åº”åˆ©ç”¨åŸŸå¤–å¹³è¡Œè¯­æ–™åº“å’Œå•è¯­è¯­æ–™åº“è¿›è¡ŒåŸŸå†…ç¿»è¯‘ï¼Œå¯¹äºåŸŸè§„èŒƒç¿»è¯‘éå¸¸é‡è¦</strong>ã€‚ æœ¬æ–‡ç»¼è¿°äº†NMTé¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯çš„æœ€æ–°è¿›å±•ã€‚</p>

<h1 id="1-introduction">1 Introduction</h1>

<p>â€‹		ç¥ç»æœºå™¨ç¿»è¯‘(NMT)ï¼ˆCho et al.ï¼Œ2014ï¼›Sutskever et al.ï¼Œ2014ï¼›Bahdanau et al.ï¼Œ2015ï¼‰å…è®¸å¯¹ç¿»è¯‘ç³»ç»Ÿè¿›è¡Œç«¯åˆ°ç«¯çš„è®­ç»ƒï¼Œè€Œä¸éœ€è¦å¤„ç†å•è¯å¯¹é½ï¼Œç¿»è¯‘è§„åˆ™å’Œå¤æ‚çš„è§£ç ç®—æ³•ï¼Œè¿™äº›éƒ½æ˜¯ç»Ÿè®¡æœºå™¨ç¿»è¯‘(SMT)ç³»ç»Ÿçš„ç‰¹å¾ï¼ˆKoehn et al.ï¼Œ2007ï¼‰ã€‚ NMTåœ¨èµ„æºä¸°å¯Œçš„åœºæ™¯ä¸‹äº§ç”Ÿäº†æœ€å…ˆè¿›çš„ç¿»è¯‘æ€§èƒ½ï¼ˆBojar et al.ï¼Œ2017ï¼›Nakazawa et al.ï¼Œ2017ï¼‰ã€‚ ç„¶è€Œï¼Œç›®å‰ï¼Œè§„æ¨¡è¶³å¤Ÿçš„é«˜è´¨é‡å¹³è¡Œè¯­æ–™åº“ä»…é€‚ç”¨äºå°‘æ•°å‡ ç§è¯­è¨€å¯¹ï¼Œå¦‚ä¸è‹±è¯­å’Œå‡ ç§æ¬§æ´²è¯­è¨€å¯¹é…å¯¹çš„è¯­è¨€ã€‚ æ­¤å¤–ï¼Œå¯¹äºæ¯ç§è¯­è¨€å¯¹ï¼Œé¢†åŸŸä¸“ç”¨è¯­æ–™åº“çš„å¤§å°å’Œå¯ç”¨é¢†åŸŸçš„æ•°é‡éƒ½æ˜¯æœ‰é™çš„ã€‚ å› æ­¤ï¼Œå¯¹äºå¤§å¤šæ•°è¯­è¨€å¯¹å’Œé¢†åŸŸï¼Œåªæœ‰å¾ˆå°‘æˆ–æ²¡æœ‰å¹³è¡Œè¯­æ–™åº“å¯ç”¨ã€‚ ä¼—æ‰€å‘¨çŸ¥ï¼Œåœ¨ä½èµ„æºåœºæ™¯ä¸‹ï¼Œvanilla SMTå’ŒNMTåœ¨é¢†åŸŸè§„èŒƒç¿»è¯‘æ–¹é¢è¡¨ç°è¾ƒå·®ï¼ˆDuhç­‰äººï¼Œ2013å¹´ï¼›Sennrichç­‰äººï¼Œ2013å¹´ï¼›Zophç­‰äººï¼Œ2016å¹´ï¼›Koehnå’ŒKnowlesï¼Œ2017å¹´ï¼‰ã€‚</p>

<p>â€‹		é«˜è´¨é‡é¢†åŸŸç‰¹å®šæœºå™¨ç¿»è¯‘(MT)ç³»ç»Ÿçš„éœ€æ±‚å¾ˆé«˜ï¼Œè€Œé€šç”¨æœºå™¨ç¿»è¯‘çš„åº”ç”¨æœ‰é™ã€‚ æ­¤å¤–ï¼Œé€šç”¨ç¿»è¯‘ç³»ç»Ÿé€šå¸¸æ€§èƒ½è¾ƒå·®ï¼Œå› æ­¤å¼€å‘ç‰¹å®šé¢†åŸŸçš„ç¿»è¯‘ç³»ç»Ÿéå¸¸é‡è¦ï¼ˆKoehn and Knowlesï¼Œ2017ï¼‰ã€‚ ==åˆ©ç”¨åŸŸå¤–å¹³è¡Œè¯­æ–™åº“å’ŒåŸŸå†…å•è¯­è¯­æ–™åº“æ”¹è¿›åŸŸå†…ç¿»è¯‘è¢«ç§°ä¸ºåŸŸé€‚åº”ç¿»è¯‘ï¼ˆWang et al.ï¼Œ2016ï¼›Chu et al.ï¼Œ2018ï¼‰==ã€‚ ä¾‹å¦‚ï¼Œ<strong>æ±‰è‹±ä¸“åˆ©é¢†åŸŸå¹³è¡Œè¯­æ–™åº“æœ‰100ä¸‡ä¸ªå¥å­å¯¹ï¼ˆGoto et al.ï¼Œ2013ï¼‰ï¼Œè€Œå£è¯­é¢†åŸŸå¹³è¡Œè¯­æ–™åº“åªæœ‰20ä¸‡ä¸ªå¥å­ï¼ˆCettolo et al.ï¼Œ2015ï¼‰ã€‚ MTé€šå¸¸åœ¨èµ„æºè´«ä¹æˆ–é¢†åŸŸä¸åŒ¹é…çš„åœºæ™¯ä¸­è¡¨ç°è¾ƒå·®ï¼Œå› æ­¤é‡è¦çš„æ˜¯åˆ©ç”¨å£è¯­é¢†åŸŸæ•°æ®å’Œä¸“åˆ©é¢†åŸŸæ•°æ®ï¼ˆChu et al.ï¼Œ2017ï¼‰ã€‚ æ­¤å¤–ï¼Œå¯¹äºå£è¯­é¢†åŸŸï¼Œæœ‰åŒ…å«æ•°ç™¾ä¸‡å¥å­çš„å•è¯­è¯­æ–™åº“ï¼Œè¿™ä¹Ÿæ˜¯å¯ä»¥åˆ©ç”¨çš„ï¼ˆSennrich et al.ï¼Œ2016b)</strong>ã€‚</p>

<p>â€‹		é¢å‘SMTçš„é¢†åŸŸé€‚é…ç ”ç©¶å¾ˆå¤šï¼Œä¸»è¦å¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±»:ä»¥æ•°æ®ä¸ºä¸­å¿ƒå’Œä»¥æ¨¡å‹ä¸ºä¸­å¿ƒã€‚ ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•ä¾§é‡äºä»åŸºäºè¯­è¨€æ¨¡å‹(LM)çš„é¢†åŸŸå¤–å¹¶è¡Œè¯­æ–™åº“ä¸­é€‰æ‹©è®­ç»ƒæ•°æ®ï¼ˆMoore and Lewisï¼Œ2010ï¼›Axelrod et al.ï¼Œ2011ï¼›Duh et al.ï¼Œ2013ï¼›Hoang and Simaanï¼Œ2014ï¼›Durrani et al.ï¼Œ2015ï¼›Chen et al.ï¼Œ2016ï¼‰æˆ–ç”Ÿæˆä¼ªå¹¶è¡Œæ•°æ®ï¼ˆUtiyama and Isaharaï¼Œ2003ï¼›Wang et al.ï¼Œ2014ï¼›Chuï¼Œ2015ï¼›Wang et al.ï¼Œ2016ï¼›Marie and Fujitaï¼Œ2017ï¼‰ã€‚ ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ–¹æ³•åœ¨æ¨¡å‹çº§åˆ«ï¼ˆSennrich et al.ï¼Œ2013ï¼›Durrani et al.ï¼Œ2015ï¼›Imamura and Sumitaï¼Œ2016ï¼‰æˆ–å®ä¾‹çº§åˆ«ï¼ˆMatsoukas et al.ï¼Œ2009ï¼›Foster et al.ï¼Œ2010ï¼›Shah et al.ï¼Œ2010ï¼›Rousseau et al.ï¼Œ2011ï¼›Zhou et al.ï¼Œ2015ï¼‰å†…æ’åŸŸå†…å’ŒåŸŸå¤–æ¨¡å‹ã€‚ ç„¶è€Œï¼Œç”±äºSMTå’ŒNMTçš„ä¸åŒç‰¹ç‚¹ï¼Œè®¸å¤šé’ˆå¯¹SMTå¼€å‘çš„æ–¹æ³•å¹¶ä¸èƒ½ç›´æ¥åº”ç”¨äºNMTã€‚</p>

<p>â€‹		NMTé¢†åŸŸé€‚é…æ˜¯ä¸€ä¸ªæ¯”è¾ƒæ–°çš„é—®é¢˜ï¼Œå·²ç»å¼•èµ·äº†ç ”ç©¶ç•Œçš„å¹¿æ³›å…³æ³¨ã€‚ è¿‘ä¸¤å¹´æ¥ï¼ŒNMTå·²ç»æˆä¸ºæœ€æµè¡Œçš„MTæ–¹æ³•ï¼Œè®¸å¤šé¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯è¢«æå‡ºå’Œè¯„ä¼°ã€‚ è¿™äº›ç ”ç©¶è¦ä¹ˆå€Ÿç”¨ä»¥å¾€SMTç ”ç©¶çš„æ€æƒ³å¹¶å°†è¿™äº›æ€æƒ³åº”ç”¨äºNMTï¼Œè¦ä¹ˆä¸ºNMTå¼€å‘ç‹¬ç‰¹çš„æ–¹æ³•ã€‚ å°½ç®¡NMTçš„é¢†åŸŸé€‚åº”å‘å±•è¿…é€Ÿï¼Œä½†æ²¡æœ‰ä¸€ä¸ªå•ä¸€çš„æ±‡ç¼–æ€»ç»“å’Œåˆ†ç±»æ‰€æœ‰çš„æ–¹æ³•ã€‚ ç”±äºè¿™æ ·çš„ç ”ç©¶å°†æå¤§åœ°é€ ç¦äºç¤¾åŒºï¼Œæˆ‘ä»¬åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ä»‹ç»äº†æ‰€æœ‰ä¸»è¦çš„NMTé¢†åŸŸé€‚é…æŠ€æœ¯ã€‚ æœ‰é’ˆå¯¹NMTçš„è°ƒæŸ¥è®ºæ–‡ï¼ˆNeubigï¼Œ2017ï¼›Koehnï¼Œ2017ï¼‰ï¼› ä½†æ˜¯ï¼Œä»–ä»¬ä¾§é‡äºä¸€èˆ¬çš„NMTå’Œæ›´å¤šæ ·çš„é¢˜ç›®ã€‚ å·²ç»ä»è®¡ç®—æœºè§†è§‰ï¼ˆCsurkaï¼Œ2017ï¼‰å’Œæœºå™¨å­¦ä¹ ï¼ˆPan and Yangï¼Œ2010ï¼›Weiss et al.ï¼Œ2016ï¼‰çš„è§’åº¦è¿›è¡Œäº†é¢†åŸŸé€‚åº”è°ƒæŸ¥ã€‚ ç„¶è€Œï¼ŒNMTè¿˜æ²¡æœ‰åšè¿‡è¿™æ ·çš„è°ƒæŸ¥ã€‚ æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯NMTé¢†åŸŸé€‚é…çš„é¦–æ¬¡å…¨é¢è°ƒæŸ¥ã€‚</p>

<p>â€‹		æœ¬æ–‡ä¸­ï¼Œç±»ä¼¼äºSMTï¼Œæˆ‘ä»¬å°†é¢å‘NMTçš„é¢†åŸŸé€‚é…åˆ†ä¸ºä¸¤å¤§ç±»:ä»¥æ•°æ®ä¸ºä¸­å¿ƒå’Œä»¥æ¨¡å‹ä¸ºä¸­å¿ƒã€‚ ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„ç±»åˆ«ä¾§é‡äºæ­£åœ¨ä½¿ç”¨çš„æ•°æ®ï¼Œè€Œä¸æ˜¯ç”¨äºåŸŸé€‚åº”çš„ä¸“ç”¨æ¨¡å‹ã€‚ æ‰€ä½¿ç”¨çš„æ•°æ®å¯ä»¥æ˜¯åŸŸå†…å•è¯­è¯­æ–™åº“ï¼ˆZhang and Zongï¼Œ2016bï¼›Cheng et al.ï¼Œ2016ï¼›Currey et al.ï¼Œ2017ï¼›Domhan and Hieberï¼Œ2017ï¼‰ï¼Œåˆæˆè¯­æ–™åº“ï¼ˆSennrich et al.ï¼Œ2016bï¼›Zhang and Zongï¼Œ2016bï¼›Park et al.ï¼Œ2017ï¼‰æˆ–å¹³è¡Œè¯­æ–™åº“ï¼ˆChu et al.ï¼Œ2017ï¼›Sajjad et al.ï¼Œ2017ï¼›Britz et al.ï¼Œ2017ï¼›Wang et al.ï¼Œ2017aï¼›van der Wees et al.ï¼Œ2017ï¼‰ã€‚ å¦ä¸€æ–¹é¢ï¼Œä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„ç±»åˆ«å…³æ³¨ä¸“é—¨ç”¨äºåŸŸè‡ªé€‚åº”çš„NMTæ¨¡å‹ï¼Œå…¶å¯ä»¥æ˜¯è®­ç»ƒç›®æ ‡ï¼ˆLuong and Manningï¼Œ2015ï¼›Sennrich et al.ï¼Œ2016bï¼›Servan et al.ï¼Œ2016ï¼›Freitag and Al-Onaizanï¼Œ2016ï¼›Wang et al.ï¼Œ2017bï¼›Chen et al.ï¼Œ2017aï¼›Vargaï¼Œ2017ï¼›Dakwale and Monzï¼Œ2017ï¼›Chu et al.ï¼Œ2017ï¼›Miceli Barone et al.ï¼Œ2017ï¼‰ï¼ŒNMTä½“ç³»ç»“æ„ï¼ˆKobus et al.ï¼Œ2016ï¼›GÃ¼ulc Ehre et al.ï¼Œ2015ï¼›Britz et al.ï¼Œ2017ï¼‰æˆ–è§£ç ç®—æ³•ï¼ˆGÃ¼ulc Ehre et al.ï¼Œ2015ï¼›Dakwale and Monzï¼Œ2017ï¼› è¿™ä¸¤ä¸ªç±»åˆ«çš„æ¦‚è¿°å¦‚å›¾1æ‰€ç¤ºã€‚ æ³¨æ„ï¼Œç”±äºä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ–¹æ³•ä¹Ÿä½¿ç”¨å•è¯­æˆ–å¹³è¡Œè¯­æ–™åº“ï¼Œè¿™ä¸¤ç±»ä¹‹é—´å­˜åœ¨é‡å ã€‚</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716144751.png" alt="image-20200716144751506" /></p>

<p>â€‹		æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ç»“æ„å¦‚ä¸‹:æˆ‘ä»¬é¦–å…ˆç®€è¦ä»‹ç»äº†NMTï¼Œå¹¶æè¿°äº†NMTä¸­ä½èµ„æºåŸŸå’Œä½èµ„æºè¯­è¨€å·®å¼‚çš„åŸå› ï¼ˆç¬¬2èŠ‚ï¼‰ï¼› æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç®€è¦å›é¡¾äº†SMTé¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯çš„å†å²å‘å±•ï¼ˆç¬¬3èŠ‚ï¼‰ï¼› åœ¨è¿™äº›èƒŒæ™¯çŸ¥è¯†çš„åŸºç¡€ä¸Šï¼Œè¯¦ç»†ä»‹ç»å’Œæ¯”è¾ƒäº†NMTé¢†åŸŸè‡ªé€‚åº”æ–¹æ³•ï¼ˆç¬¬4èŠ‚ï¼‰ï¼› ç„¶åï¼Œæˆ‘ä»¬ä»‹ç»äº†åœ¨çœŸå®å•è¯åœºæ™¯ä¸­NMTçš„é¢†åŸŸè‡ªé€‚åº”ï¼Œè¿™å¯¹MTçš„å®é™…åº”ç”¨è‡³å…³é‡è¦ï¼ˆç¬¬5èŠ‚ï¼‰ï¼› æœ€åï¼Œæˆ‘ä»¬å¯¹æœ¬é¢†åŸŸæœªæ¥çš„ç ”ç©¶æ–¹å‘æå‡ºäº†è‡ªå·±çš„çœ‹æ³•ï¼ˆç¬¬6èŠ‚ï¼‰ï¼Œå¹¶å¯¹æœ¬æ–‡è¿›è¡Œäº†æ€»ç»“ï¼ˆç¬¬7èŠ‚ï¼‰ã€‚</p>

<h1 id="2-neural-machine-translation">2 Neural Machine Translation</h1>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716144810.png" alt="image-20200716144810366" /></p>

<p>â€‹		NMTæ˜¯ä¸€ç§ç”¨äºä»ä¸€ç§è¯­è¨€ç¿»è¯‘åˆ°å¦ä¸€ç§è¯­è¨€çš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œå®ƒä¾èµ–äºæ·±åº¦å­¦ä¹ æ¥è®­ç»ƒç¿»è¯‘æ¨¡å‹ï¼ˆCho et al.ï¼Œ2014ï¼›Sutskever et al.ï¼Œ2014ï¼›Bahdanau et al.ï¼Œ2015ï¼‰ã€‚ å…·æœ‰æ³¨æ„åŠ›çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼ˆBahdanauç­‰äººï¼Œ2015ï¼‰æ˜¯æœ€å¸¸ç”¨çš„NMTæ¶æ„ã€‚ è¿™ç§æ¨¡å¼ä¹Ÿè¢«ç§°ä¸ºRNNSearchã€‚ å›¾2æè¿°äº†RNNsearchæ¨¡å‹ï¼ˆBahdanauç­‰äººï¼Œ2015ï¼‰ï¼Œå®ƒæ¥å—è¾“å…¥è¯­å¥x={x1ï¼Œã€‚ã€‚ã€‚ï¼Œx n}åŠå…¶ç¿»è¯‘y={y1ï¼Œã€‚ã€‚ã€‚ï¼Œy m}ã€‚ è½¬æ¢ç”Ÿæˆä¸º:</p>

<p><img src="/Users/suntian/Library/Application Support/typora-user-images/image-20200526164307859.png" alt="image-20200526164307859" /></p>

<p>â€‹		å…¶ä¸­ï¼Ÿæ˜¯ä¸€ç»„å‚æ•°ï¼Œmæ˜¯yä¸­çš„å…¨éƒ¨å­—æ•°ï¼Œy jæ˜¯å½“å‰é¢„æµ‹å­—ï¼Œy&lt;jæ˜¯å…ˆå‰é¢„æµ‹å­—ã€‚ å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå¹³è¡Œè¯­æ–™åº“Cï¼Œç”±ä¸€ç»„å¹³è¡Œå¥å¯¹ï¼ˆxï¼Œyï¼‰ç»„æˆã€‚ è®­ç»ƒç›®æ ‡æ˜¯æœ€å°åŒ–äº’ç†µæŸå¤±L W.R.Tï¼Ÿ:</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716144631.png" alt="image-20200716144631212" />		è¯¥æ¨¡å‹ç”±ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼Œå³ç¼–ç å™¨ï¼Œè§£ç å™¨å’Œæ³¨æ„æ¨¡å‹ã€‚ ç¼–ç å™¨ä½¿ç”¨åµŒå…¥æœºåˆ¶å°†å•è¯è½¬æ¢ä¸ºå®ƒä»¬çš„è¿ç»­ç©ºé—´è¡¨ç¤ºã€‚ è¿™äº›åµŒå…¥æœ¬èº«å¹¶ä¸åŒ…å«å•è¯ä¹‹é—´çš„å…³ç³»å’Œå®ƒä»¬åœ¨å¥å­ä¸­çš„ä½ç½®çš„ä¿¡æ¯ã€‚ ä½¿ç”¨é€’å½’ç¥ç»ç½‘ç»œ(RNN)å±‚ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯é—¨æ§é€’å½’å•å…ƒ(GRU)ï¼Œå¯ä»¥å®ç°è¿™ä¸€ç‚¹ã€‚ ä¸€ä¸ªRNNä¿æŒä¸€ä¸ªéšè—çŠ¶æ€ï¼ˆä¹Ÿç§°ä¸ºè®°å¿†æˆ–å†å²ï¼‰ï¼Œè¿™å…è®¸å®ƒä¸ºä¸€ä¸ªå•è¯ç”Ÿæˆä¸€ä¸ªè¿ç»­çš„ç©ºé—´è¡¨ç¤ºï¼Œç»™å®šæ‰€æœ‰å·²ç»çœ‹åˆ°çš„è¿‡å»çš„å•è¯ã€‚ æœ‰ä¸¤ä¸ªGRUå±‚ï¼Œåˆ†åˆ«ç¼–ç å‰å‘å’Œåå‘ä¿¡æ¯ã€‚ æ¯ä¸ªå­—x ié€šè¿‡å°†å‰å‘éšè—çŠ¶æ€h iå’Œåå‘éšè—çŠ¶æ€h içº§è”ä¸ºh i=[h iï¼›h i]æ¥è¡¨ç¤ºã€‚ è¿™æ ·ï¼Œæºå¥å­x={x1ï¼Œã€‚ã€‚ã€‚ï¼Œx n}å¯ä»¥è¡¨ç¤ºä¸ºh={h1ï¼Œã€‚ã€‚ã€‚ï¼Œh n}ã€‚ é€šè¿‡ä½¿ç”¨å‰å‘å’Œåå‘é€’å½’ä¿¡æ¯ï¼Œåœ¨ç»™å®šå•è¯å‰åçš„æ‰€æœ‰å•è¯çš„æƒ…å†µä¸‹ï¼Œè·å¾—å•è¯çš„è¿ç»­ç©ºé—´è¡¨ç¤ºã€‚</p>

<p>â€‹		è§£ç å™¨åœ¨æ¦‚å¿µä¸Šæ˜¯ä¸€ä¸ªRNNè¯­è¨€æ¨¡å‹(RNNLM)ï¼Œå…·æœ‰è‡ªå·±çš„åµŒå…¥æœºåˆ¶ï¼Œä¸€ä¸ªGRUå±‚ç”¨æ¥è®°å¿†å…ˆå‰ç”Ÿæˆçš„å•è¯ï¼Œä¸€ä¸ªsoftmaxå±‚ç”¨æ¥é¢„æµ‹ä¸€ä¸ªç›®æ ‡å•è¯ã€‚ ç¼–ç å™¨å’Œè§£ç å™¨é€šè¿‡ä½¿ç”¨å…³æ³¨æœºåˆ¶æ¥è€¦åˆï¼Œè¯¥å…³æ³¨æœºåˆ¶è®¡ç®—ç”±ç¼–ç å™¨äº§ç”Ÿçš„åå¤è¡¨ç¤ºçš„åŠ æƒå¹³å‡å€¼ï¼Œä»è€Œå……å½“è½¯å¯¹å‡†æœºåˆ¶ã€‚ è¿™ä¸ªåŠ æƒå¹³å‡å‘é‡ï¼Œä¹Ÿç§°ä¸ºä¸Šä¸‹æ–‡æˆ–æ³¨æ„åŠ›å‘é‡ï¼Œä¸å…ˆå‰é¢„æµ‹çš„å•è¯ä¸€èµ·è¢«é¦ˆé€åˆ°è§£ç å™¨GRUä»¥äº§ç”Ÿä¸€ä¸ªè¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºè¢«ä¼ é€’åˆ°softmaxå±‚ä»¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚ åœ¨ç­‰å¼ä¸­ï¼Œç”¨äºè§£ç å™¨çš„æ—¶é—´jçš„RNNéšè—çŠ¶æ€s jè®¡ç®—å¦‚ä¸‹:</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716145204.png" alt="image-20200716144647241" /></p>

<p>â€‹		å…¶ä¸­fæ˜¯GRUçš„æ¿€æ´»å‡½æ•°ï¼Œsj-1æ˜¯å‰ä¸€RNNéšè—çŠ¶æ€ï¼Œyj-1æ˜¯å‰ä¸€å­—ï¼Œcjæ˜¯ä¸Šä¸‹æ–‡å‘é‡ã€‚ c jé€šè¿‡ä½¿ç”¨å¯¹å‡†æƒé‡a jiè®¡ç®—ä¸ºç¼–ç å™¨éšè—çŠ¶æ€h={h1ï¼Œã€‚ã€‚ã€‚ï¼Œh n}çš„åŠ æƒå’Œ:</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716144658.png" alt="image-20200716144658420" /></p>

<p>â€‹		å…¶ä¸­aæ˜¯å¯¹ä½ç½®iå‘¨å›´çš„è¾“å…¥å’Œä½ç½®Jå¤„çš„è¾“å‡ºçš„åŒ¹é…æ°´å¹³è¿›è¡Œè¯„åˆ†çš„å¯¹å‡†æ¨¡å‹ã€‚ softmaxå±‚åŒ…å«maxoutå±‚ï¼Œå®ƒæ˜¯å…·æœ‰maxæ± çš„å‰é¦ˆå±‚ã€‚ maxoutå±‚é‡‡ç”¨è§£ç å™¨GRUç”Ÿæˆçš„å¾ªç¯éšè—çŠ¶æ€ï¼Œå‰ä¸€ä¸ªå­—å’Œä¸Šä¸‹æ–‡å‘é‡æ¥è®¡ç®—ä¸€ä¸ªæ•´ä½“è¡¨ç¤ºï¼Œå¹¶å°†å…¶é¦ˆé€åˆ°ä¸€ä¸ªç®€å•çš„softmaxå±‚:</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716144710.png" alt="image-20200716144710001" /></p>

<p>â€‹		ç”±äºç¼–ç å™¨ï¼Œè§£ç å™¨å’Œæ³¨æ„åŠ›æ¨¡å‹ä¸­çš„å¤§é‡å‚æ•°ï¼Œéœ€è¦å¤§é‡çš„å¹¶è¡Œè¯­æ–™åº“æ¥è®­ç»ƒNMTç³»ç»Ÿä»¥é¿å…è¿‡åº¦ç­›é€‰ã€‚ è¿™æ˜¯ä½èµ„æºåŸŸå’Œè¯­è¨€NMTçš„ä¸»è¦ç“¶é¢ˆã€‚</p>

<h1 id="3-domain-adaptation-for-smt">3 Domain Adaptation for SMT</h1>

<p>â€‹		åœ¨SMTä¸­ï¼Œäººä»¬æå‡ºäº†è®¸å¤šé¢†åŸŸè‡ªé€‚åº”æ–¹æ³•ï¼Œä»¥å…‹æœåœ¨ç‰¹å®šé¢†åŸŸå’Œè¯­è¨€ä¸­ç¼ºä¹å¤§é‡æ•°æ®çš„é—®é¢˜ã€‚ å¤§å¤šæ•°SMTåŸŸé€‚é…æ–¹æ³•å¯ä»¥å¤§è‡´åˆ†ä¸ºä¸¤å¤§ç±»:</p>

<h2 id="31-data-centric">3.1 Data Centric</h2>

<p>æ­¤ç±»åˆ«ä¾§é‡äºä½¿ç”¨ç°æœ‰çš„åŸŸå†…æ•°æ®é€‰æ‹©æˆ–ç”Ÿæˆä¸åŸŸç›¸å…³çš„æ•°æ®ã€‚</p>

<p>iï¼‰å½“å­˜åœ¨æ¥è‡ªå…¶ä»–é¢†åŸŸçš„æœ‰æ•ˆå¹¶è¡Œè¯­æ–™åº“æ—¶ï¼Œä¸»è¦æ€æƒ³æ˜¯ä½¿ç”¨ä»åŸŸå†…å’ŒåŸŸå¤–æ•°æ®è®­ç»ƒçš„æ¨¡å‹å¯¹åŸŸå¤–æ•°æ®è¿›è¡Œè¯„åˆ†ï¼Œå¹¶ä½¿ç”¨æ‰€å¾—è¯„åˆ†çš„æˆªæ­¢é˜ˆå€¼ä»åŸŸå¤–æ•°æ®ä¸­é€‰æ‹©è®­ç»ƒæ•°æ®ã€‚LMsï¼ˆMoore and Lewisï¼Œ2010ï¼› Axelrodç­‰äººï¼Œ2011å¹´ï¼› Duhç­‰äººï¼Œ2013å¹´ï¼‰ï¼Œä»¥åŠè”åˆæ¨¡å‹ï¼ˆHoangå’ŒSimaanï¼Œ2014å¹´ï¼› Durraniç­‰äººï¼Œ2015ï¼‰ï¼Œä»¥åŠæ›´è¿‘çš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ¨¡å‹ï¼ˆChenç­‰äººï¼Œ2016ï¼‰å¯ä»¥ç”¨æ¥ç»™å¥å­æ‰“åˆ†ã€‚</p>

<p>iiï¼‰å½“å¹³è¡Œè¯­æ–™ä¸è¶³æ—¶ï¼Œä¹Ÿæœ‰ç ”ç©¶ä½¿ç”¨ä¿¡æ¯æ£€ç´¢ï¼ˆUtiyamaå’ŒIsaharaï¼Œ2003ï¼‰ï¼Œè‡ªæˆ‘å¢å¼ºï¼ˆLambertç­‰äººï¼Œ2011ï¼‰æˆ–å¹³è¡Œè¯åµŒå…¥ï¼ˆMarieå’ŒFujitaï¼‰ç”Ÿæˆä¼ªå¹³è¡Œå¥å­ã€‚ ï¼Œ2017ï¼‰ã€‚ é™¤äº†å¥å­ç”Ÿæˆä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›ç ”ç©¶ç”Ÿæˆå•è¯­è¨€n-gramï¼ˆWangç­‰ï¼Œ2014ï¼‰å’Œå¹¶è¡ŒçŸ­è¯­å¯¹ï¼ˆChuï¼Œ2015ï¼› Wangç­‰ï¼Œ2016ï¼‰ã€‚</p>

<p>SMTä¸­å¤§å¤šæ•°åŸºäºæ•°æ®ä¸­å¿ƒçš„æ–¹æ³•éƒ½å¯ä»¥ç›´æ¥åº”ç”¨äºNMTã€‚ ä½†æ˜¯ï¼Œè¿™äº›æ–¹æ³•å¤§å¤šæ•°éƒ½é‡‡ç”¨ä¸NMTä¸ç›¸å…³çš„æ•°æ®é€‰æ‹©æˆ–ç”Ÿæˆæ ‡å‡†ã€‚ å› æ­¤ï¼Œè¿™äº›æ–¹æ³•åªèƒ½åœ¨NMTæ–¹é¢å®ç°é€‚åº¦çš„æ”¹è¿›ï¼ˆWangç­‰ï¼Œ2017aï¼‰ã€‚</p>

<h2 id="32-model-centric">3.2 Model Centric</h2>

<p>æ­¤ç±»åˆ«é‡ç‚¹åœ¨äºå¯¹æ¥è‡ªä¸åŒåŸŸçš„æ¨¡å‹è¿›è¡Œæ’å€¼ã€‚</p>

<p>iï¼‰æ¨¡å‹çº§æ’å€¼ã€‚è®­ç»ƒäº†åˆ†åˆ«å¯¹åº”äºæ¯ä¸ªè¯­æ–™åº“çš„å‡ ç§SMTæ¨¡å‹ï¼Œä¾‹å¦‚LMï¼Œç¿»è¯‘æ¨¡å‹å’Œé‡æ–°æ’åºæ¨¡å‹ã€‚ç„¶åå°†è¿™äº›æ¨¡å‹ç»„åˆä»¥è·å¾—æœ€ä½³æ€§èƒ½ï¼ˆFosterå’ŒKuhnï¼Œ2007; Bisazzaç­‰äººï¼Œ2011; Niehueså’ŒWaibelï¼Œ2012; Sennrichç­‰äººï¼Œ2013; Durraniç­‰äººï¼Œ2015; Imamuraå’ŒSumitaï¼Œ2016ï¼‰ ã€‚</p>

<p>iiï¼‰å®ä¾‹çº§åˆ«æ’å€¼ã€‚å®ä¾‹åŠ æƒå·²åº”ç”¨äºå‡ ç§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰åŸŸé€‚åº”ä»»åŠ¡ï¼ˆJiangå’ŒZhaiï¼Œ2007ï¼‰ï¼Œå°¤å…¶æ˜¯SMTï¼ˆMatsoukasç­‰ï¼Œ2009ï¼› Fosterç­‰ï¼Œ2010ï¼› Shahç­‰ï¼Œ2012ï¼› Mansourå’ŒNeyï¼Œ2012ï¼› Zhouç­‰ï¼Œ2015ï¼‰ã€‚ä»–ä»¬é¦–å…ˆé€šè¿‡ä½¿ç”¨è§„åˆ™æˆ–ç»Ÿè®¡æ–¹æ³•ä¸ºæƒé‡å¯¹æ¯ä¸ªå®ä¾‹/åŸŸè¯„åˆ†ï¼Œç„¶åé€šè¿‡ä¸ºæ¯ä¸ªå®ä¾‹/åŸŸèµ‹äºˆæƒé‡æ¥è®­ç»ƒSMTæ¨¡å‹ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡æ•°æ®é‡æ–°é‡‡æ ·å¯¹è¯­æ–™åº“åŠ æƒï¼ˆShahç­‰äººï¼Œ2010ï¼› Rousseauç­‰äººï¼Œ2011ï¼‰ã€‚</p>

<p>å¯¹äºNMTï¼ŒåƒSMTä¸€æ ·ï¼Œå·²ç»æå‡ºäº†å‡ ç§æ’å€¼æ¨¡å‹/æ•°æ®çš„æ–¹æ³•ã€‚å¯¹äºæ¨¡å‹çº§æ’å€¼ï¼Œæœ€ç›¸å…³çš„NMTæŠ€æœ¯æ˜¯æ¨¡å‹é›†æˆï¼ˆJeanç­‰ï¼Œ2015ï¼‰ã€‚å¯¹äºå®ä¾‹çº§æ’å€¼ï¼Œæœ€ç›¸å…³çš„æ–¹æ³•æ˜¯åœ¨NMTç›®æ ‡å‡½æ•°ä¸­åˆ†é…æƒé‡ï¼ˆChenç­‰ï¼Œ2017a; Wangç­‰ï¼Œ2017bï¼‰ã€‚ä½†æ˜¯ï¼ŒSMTå’ŒNMTçš„æ¨¡å‹ç»“æ„å®Œå…¨ä¸åŒã€‚ SMTæ˜¯å‡ ç§ç‹¬ç«‹æ¨¡å‹çš„ç»„åˆï¼›ç›¸æ¯”ä¹‹ä¸‹ï¼ŒNMTæœ¬èº«å°±æ˜¯ä¸€ä¸ªä¸å¯æˆ–ç¼ºçš„æ¨¡å‹ã€‚å› æ­¤ï¼Œè¿™äº›æ–¹æ³•å¤§å¤šæ•°ä¸èƒ½ç›´æ¥åº”ç”¨äºNMTã€‚</p>

<h1 id="4-domain-adaptation-for-nmt">4 Domain Adaptation for NMT</h1>

<h2 id="41-data-centric">4.1 Data Centric</h2>

<h3 id="411-using-monolingual-corpora">4.1.1. Using Monolingual Corpora</h3>

<p>â€‹		ä¸SMTä¸åŒçš„æ˜¯ï¼ŒåŸŸå†…å•è¯­æ•°æ®ä¸èƒ½ç›´æ¥ä½œä¸ºå¸¸è§„NMTçš„LMï¼Œä¸ºæ­¤å·²è¿›è¡Œäº†è®¸å¤šç ”ç©¶ã€‚ GÃ¼ulccoverehreç­‰äººã€‚ ï¼ˆ2015å¹´ï¼‰åœ¨å•è¯­æ•°æ®ä¸Šè®­ç»ƒRNNLMï¼Œå¹¶èåˆRNNLMå’ŒNMTæ¨¡å‹ã€‚ ç§‘é‡Œç­‰äººã€‚ ï¼ˆ2017ï¼‰å°†ç›®æ ‡å•è¯­æ•°æ®å¤åˆ¶åˆ°æºç«¯ï¼Œå¹¶å°†å¤åˆ¶çš„æ•°æ®ç”¨äºè®­ç»ƒNMTã€‚ Domhanå’ŒHieber(2017)æå‡ºå°†ç›®æ ‡å•è¯­æ•°æ®ç”¨äºå…·æœ‰LMå’ŒNMTå¤šä»»åŠ¡å­¦ä¹ çš„è§£ç å™¨ã€‚ Zhangå’ŒZong(2016b)ä½¿ç”¨æºç«¯å•è¯­æ•°æ®é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æ¥å¢å¼ºNMTç¼–ç å™¨ï¼Œç”¨äºé¢„æµ‹ç¿»è¯‘å’Œé‡æ–°æ’åºçš„æºå¥å­ã€‚ Chengç­‰äººã€‚ ï¼ˆ2016ï¼‰é€šè¿‡ä½¿ç”¨NMTä½œä¸ºè‡ªåŠ¨ç¼–ç å™¨é‡å»ºå•è¯­æ•°æ®ï¼Œå°†æºå•è¯­æ•°æ®å’Œç›®æ ‡å•è¯­æ•°æ®åŒæ—¶ç”¨äºNMTã€‚</p>

<h3 id="412-synthetic-parallel-corpora-generation">4.1.2 Synthetic Parallel Corpora Generation</h3>

<p>â€‹		ç”±äºNMTæœ¬èº«å…·æœ‰å­¦ä¹ LMsçš„èƒ½åŠ›ï¼Œç›®æ ‡å•è¯­æ•°æ®ä¹Ÿå¯ä»¥ç”¨äºNMTç³»ç»Ÿåœ¨åè¯‘ç›®æ ‡å¥å­ååŠ å¼ºè¯‘ç å™¨ä»¥ç”Ÿæˆåˆæˆçš„å¹³è¡Œè¯­æ–™åº“ï¼ˆSennrich et al.ï¼Œ2016b)ã€‚ å›¾3æ˜¾ç¤ºäº†è¯¥æ–¹æ³•çš„æµç¨‹å›¾ã€‚ è¿˜è¡¨æ˜ï¼Œåˆæˆæ•°æ®ç”Ÿæˆå¯¹äºä½¿ç”¨ç›®æ ‡ä¾§å•è¯­æ•°æ®ï¼ˆSennrichç­‰äººï¼Œ2016c)ï¼Œæºä¾§å•è¯­æ•°æ®ï¼ˆZhangå’ŒZongï¼Œ2016b)æˆ–ä¸¤è€…ï¼ˆParkç­‰äººï¼Œ2017ï¼‰çš„åŸŸé€‚åº”éå¸¸æœ‰æ•ˆã€‚</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716144827.png" alt="image-20200716144827897" /></p>

<h3 id="413-using-out-of-domain-parallel-corpora">4.1.3 Using Out-of-Domain Parallel Corpora</h3>

<p>â€‹		é‡‡ç”¨åŸŸå†…å’ŒåŸŸå¤–å¹¶è¡Œè¯­æ–™åº“ï¼Œè®­ç»ƒä¸€ä¸ªæ—¢èƒ½æé«˜åŸŸå†…ç¿»è¯‘è´¨é‡åˆä¸é™ä½åŸŸå¤–ç¿»è¯‘è´¨é‡çš„æ··åˆåŸŸæœºå™¨ç¿»è¯‘ç³»ç»Ÿæ˜¯ç†æƒ³çš„ã€‚ æˆ‘ä»¬å°†è¿™äº›åŠªåŠ›å½’ç±»ä¸ºå¤šåŸŸæ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•å·²ç»æˆåŠŸåœ°ä¸ºNMTå¼€å‘ã€‚ æ­¤å¤–ï¼Œè¿˜æå‡ºäº†é¢å‘NMTçš„SMTæ•°æ®é€‰æ‹©æ€æƒ³ã€‚</p>

<p>â€‹		Chuç­‰äººçš„å¤šåŸŸæ–¹æ³•ã€‚ ï¼ˆ2017ï¼‰æœ€åˆæ˜¯ç”±Sennrichç­‰äººæå‡ºçš„ã€‚ (2016a)ï¼Œå®ƒä½¿ç”¨æ ‡è®°æ¥æ§åˆ¶NMTçš„ç¤¼è²Œæ€§ã€‚ è¯¥æ–¹æ³•çš„æ¦‚è¿°å¦‚å›¾6ä¸­è™šçº¿éƒ¨åˆ†æ‰€ç¤ºã€‚ åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œå¤šä¸ªåŸŸçš„è¯­æ–™åº“é€šè¿‡ä¸¤ä¸ªå°çš„ä¿®æ”¹è¿æ¥èµ·æ¥:</p>

<p>â€‹		â€¢åœ¨å„è¯­æ–™åº“çš„æºå¥ä¸­æ·»åŠ åŸŸæ ‡è®°â€œ&lt;2domain&gt;â€ã€‚ è¿™ä½¿NMTè§£ç å™¨ä¸ºç‰¹å®šåŸŸç”Ÿæˆå¥å­ã€‚</p>

<p>â€‹		â€¢å¯¹è¾ƒå°è¯­æ–™åº“è¿›è¡Œè¿‡é‡‡æ ·ï¼Œä»¥ä¾¿åŸ¹è®­ç¨‹åºå¯¹æ¯ä¸ªé¢†åŸŸç»™äºˆåŒç­‰é‡è§†ã€‚</p>

<p>â€‹		Sajjadç­‰äººã€‚ ï¼ˆ2017ï¼‰è¿›ä¸€æ­¥æ¯”è¾ƒè®­ç»ƒä¸€ä¸ªå¤šé¢†åŸŸç³»ç»Ÿçš„ä¸åŒæ–¹æ³•ã€‚ ç‰¹åˆ«åœ°ï¼Œä»–ä»¬æ¯”è¾ƒç®€å•åœ°è¿æ¥å¤šé¢†åŸŸè¯­æ–™åº“çš„è¿æ¥ï¼Œåœ¨æ¯ä¸ªé¢†åŸŸè¯­æ–™åº“ä¸Šè¿­ä»£è®­ç»ƒNMTç³»ç»Ÿçš„stakingï¼Œé€‰æ‹©ä¸é¢†åŸŸå†…æ•°æ®æ¥è¿‘çš„ä¸€ç»„é¢†åŸŸå¤–æ•°æ®çš„selectionï¼Œä»¥åŠé›†æˆç‹¬ç«‹è®­ç»ƒçš„å¤šä¸ªNMTæ¨¡å‹çš„ensembleã€‚ ä»–ä»¬è®¤ä¸ºï¼Œåœ¨åŸŸå†…æ•°æ®ä¸Šè°ƒæ•´çº§è”ç³»ç»Ÿå¯è·å¾—æœ€ä½³æ€§èƒ½ã€‚ å¸ƒé‡ŒèŒ¨ç­‰äººã€‚ ï¼ˆ2017å¹´ï¼‰å°†å¤šåŸŸæ³•ä¸ä¸€ç§åˆ¤åˆ«æ³•è¿›è¡Œæ¯”è¾ƒï¼ˆè¯¦è§4.2.2èŠ‚ï¼‰ã€‚ ç»“æœè¡¨æ˜ï¼Œåˆ¤åˆ«æ³•çš„æ€§èƒ½ä¼˜äºå¤šåŸŸæ³•ã€‚</p>

<p>â€‹		æ•°æ®é€‰æ‹©æ­£å¦‚SMTä¸€èŠ‚ï¼ˆç¬¬3.1èŠ‚ï¼‰ä¸­æåˆ°çš„ï¼ŒSMTä¸­çš„æ•°æ®é€‰æ‹©æ–¹æ³•å¯ä»¥ç•¥å¾®æé«˜NMTçš„æ€§èƒ½ï¼Œå› ä¸ºå®ƒä»¬çš„æ•°æ®é€‰æ‹©æ ‡å‡†ä¸NMTä¸æ˜¯å¾ˆç›¸å…³ï¼ˆWang et al.ï¼Œ2017a)ã€‚ ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒWangç­‰äººã€‚ (2017a)åˆ©ç”¨NMTä¸­æºå¥å­çš„å†…éƒ¨åµŒå…¥ï¼Œåˆ©ç”¨å¥å­åµŒå…¥ç›¸ä¼¼åº¦ä»åŸŸå¤–æ•°æ®ä¸­é€‰æ‹©ä¸åŸŸå†…æ•°æ®æ¥è¿‘çš„å¥å­ï¼ˆå›¾4ï¼‰ã€‚ Van der Weesç­‰äººã€‚ ï¼ˆ2017ï¼‰æå‡ºäº†ä¸€ç§åŠ¨æ€æ•°æ®é€‰æ‹©æ–¹æ³•ï¼Œå…¶ä¸­ä»–ä»¬åœ¨ä¸åŒçš„è®­ç»ƒå†å…ƒä¹‹é—´æ”¹å˜æ‰€é€‰æ‹©çš„è®­ç»ƒæ•°æ®å­é›†ç”¨äºNMTã€‚ ç»“æœè¡¨æ˜ï¼ŒåŸºäºåŸŸå†…ç›¸ä¼¼åº¦çš„è®­ç»ƒæ•°æ®é€æ¸å‡å°‘çš„æ–¹æ³•å…·æœ‰æœ€å¥½çš„æ€§èƒ½ã€‚</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716144857.png" alt="image-20200716144857822" /></p>

<p>â€‹		è™½ç„¶æ‰€æœ‰çš„ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„NMTæ–¹æ³•åœ¨åŸç†ä¸Šæ˜¯ç›¸äº’è¡¥å……çš„ï¼Œä½†ç›®å‰è¿˜æ²¡æœ‰å°è¯•å°†è¿™äº›æ–¹æ³•ç»“åˆèµ·æ¥çš„ç ”ç©¶ï¼Œè¿™è¢«è®¤ä¸ºæ˜¯æœªæ¥çš„ä¸€ä¸ªæ–¹å‘ã€‚</p>

<h2 id="42-model-centric">4.2 Model Centric</h2>

<h3 id="421-training-objective-centric">4.2.1 Training Objective Centric</h3>

<p>â€‹		æœ¬èŠ‚ä¸­çš„æ–¹æ³•æ”¹å˜äº†è·å¾—æœ€ä¼˜åŸŸå†…è®­ç»ƒç›®æ ‡çš„è®­ç»ƒå‡½æ•°æˆ–è¿‡ç¨‹ã€‚</p>

<p>â€‹			å®ä¾‹/ä»£ä»·æƒé‡NMTä¸­å®ä¾‹æƒé‡çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºNMTä¸æ˜¯çº¿æ€§æ¨¡å‹æˆ–çº¿æ€§æ¨¡å‹çš„ç»„åˆï¼Œè¿™æ„å‘³ç€å®ä¾‹æƒé‡ä¸èƒ½ç›´æ¥é›†æˆåˆ°NMTä¸­ã€‚ åœ¨NMTä¸­åªæœ‰ä¸€ä¸ªå…³äºå®ä¾‹åŠ æƒçš„å·¥ä½œï¼ˆWang et al.ï¼Œ2017b)ã€‚ ä»–ä»¬ä¸ºç›®æ ‡å‡½æ•°è®¾ç½®äº†ä¸€ä¸ªæƒé‡ï¼Œè¿™ä¸ªæƒé‡é€šè¿‡ä¸€ä¸ªåŸŸå†…LMå’Œä¸€ä¸ªåŸŸå¤–LMä»äº¤å‰ç†µä¸­å­¦ä¹ ï¼ˆAxelrodç­‰äººï¼Œ2011ï¼‰ï¼ˆå›¾5ï¼‰ã€‚ Chen et alã€‚ (2017a)ä½¿ç”¨åŸŸåˆ†ç±»å™¨ä¿®æ”¹NMTæˆæœ¬å‡½æ•°ã€‚ åŸŸåˆ†ç±»å™¨çš„è¾“å‡ºæ¦‚ç‡è½¬æ¢ä¸ºåŸŸæƒé‡ã€‚ æ­¤åˆ†ç±»å™¨ä½¿ç”¨å¼€å‘æ•°æ®è¿›è¡Œè®­ç»ƒã€‚ è¿‘æ—¥ï¼Œç‹ç­‰äººã€‚ ï¼ˆ2018ï¼‰ä¸ºNMTæå‡ºäº†ä¸€ä¸ªå¥å­é€‰æ‹©å’ŒåŠ æƒçš„è”åˆæ¡†æ¶ã€‚</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716145447.png" alt="image-20200716144915149" /></p>

<p>â€‹		å¾®è°ƒå¾®è°ƒæ˜¯åŸŸé€‚åº”çš„å¸¸è§„æ–¹å¼ï¼ˆLuongå’ŒManningï¼Œ2015ï¼›Sennrichç­‰ï¼Œ2016bï¼›Servanç­‰ï¼Œ2016ï¼›Freitagå’ŒAl-Onaizanï¼Œ2016ï¼‰ã€‚ åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œåœ¨èµ„æºä¸°å¯Œçš„åŸŸå¤–è¯­æ–™åº“ä¸Šè®­ç»ƒNMTç³»ç»Ÿç›´åˆ°æ”¶æ•›ï¼Œç„¶ååœ¨èµ„æºè´«ä¹çš„åŸŸå†…è¯­æ–™åº“ä¸Šè°ƒæ•´å…¶å‚æ•°ã€‚ é€šå¸¸ï¼Œä¼˜åŒ–åº”ç”¨äºåŸŸå†…å¹¶è¡Œè¯­æ–™åº“ã€‚ Vargaç­‰äººã€‚ ï¼ˆ2017ï¼‰å°†å…¶åº”ç”¨äºä»å¯æ¯”è¯­æ–™åº“ä¸­æå–çš„å¹³è¡Œå¥ä¸Šã€‚ é€šè¿‡ä»å¯æ¯”è¯­æ–™åº“ä¸­æå–å¹³è¡Œæ•°æ®ï¼Œå¯æ¯”è¯­æ–™åº“å·²è¢«å¹¿æ³›ç”¨äºSMTï¼ˆChuï¼Œ2015ï¼‰ã€‚ ä¸ºäº†é˜²æ­¢åŸŸå†…æ•°æ®è°ƒä¼˜åçš„åŸŸå¤–è½¬æ¢é€€åŒ–ï¼ŒDakwaleå’ŒMonz(2017)æå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†è’¸é¦çš„åŸŸå¤–æ¨¡å‹åˆ†å¸ƒçš„æ‰©å±•è°ƒä¼˜ï¼ˆè¾›é¡¿ç­‰äººï¼Œ2015ï¼‰ã€‚</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716145456.png" alt="image-20200716144933626" /></p>

<p>â€‹		æ··åˆå¾®è°ƒè¯¥æ–¹æ³•æ˜¯å¤šåŸŸå’ŒéåŸŸè°ƒè°æ–¹æ³•çš„ç»„åˆï¼ˆå›¾6ï¼‰ã€‚ åŸ¹è®­ç¨‹åºå¦‚ä¸‹:</p>

<p>â€‹		1.åœ¨åŸŸå¤–æ•°æ®ä¸Šè®­ç»ƒNMTæ¨¡å‹ï¼Œç›´åˆ°æ”¶æ•›ã€‚</p>

<p>â€‹		2.åœ¨åŸŸå†…å’ŒåŸŸå¤–æ•°æ®çš„æ··åˆä¸Šï¼ˆé€šè¿‡å¯¹åŸŸå†…æ•°æ®è¿›è¡Œè¿‡é‡‡æ ·ï¼‰æ¢å¤ä»æ­¥éª¤1å¼€å§‹çš„NMTæ¨¡å‹çš„è®­ç»ƒï¼Œç›´åˆ°æ”¶æ•›ã€‚</p>

<p>â€‹		æ··åˆè°ƒè°è§£å†³äº†åŸŸå†…æ•°æ®å°è€Œå¯¼è‡´çš„è¿‡åº¦è°ƒè°é—®é¢˜ã€‚ ä¸è®­ç»ƒå¤šåŸŸæ¨¡å‹ç›¸æ¯”ï¼Œç”¨åŸŸå¤–æ•°æ®è®­ç»ƒä¸€ä¸ªå¥½çš„æ¨¡å‹æ›´å®¹æ˜“ã€‚ ä¸€æ—¦æˆ‘ä»¬è·å¾—äº†è‰¯å¥½çš„æ¨¡å‹å‚æ•°ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨è¿™äº›å‚æ•°å¯¹æ··åˆåŸŸæ•°æ®è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œä¸ºåŸŸå†…æ¨¡å‹è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚ æ­¤å¤–ï¼Œæ··åˆè°ƒä¼˜æ¯”å¤šåŸŸè°ƒä¼˜æ›´å¿«ï¼Œå› ä¸ºè®­ç»ƒåŸŸå¤–æ¨¡å‹æ¯”è®­ç»ƒå¤šåŸŸæ¨¡å‹æ”¶æ•›æ›´å¿«ï¼Œè€Œå¤šåŸŸæ¨¡å‹åœ¨æ··åˆåŸŸæ•°æ®è°ƒä¼˜æ—¶æ”¶æ•›ä¹Ÿéå¸¸å¿«ã€‚ Chuç­‰äººã€‚ ï¼ˆ2017å¹´ï¼‰è¡¨æ˜ï¼Œæ··åˆè°ƒä¼˜æ¯”å¤šåŸŸè°ƒä¼˜å’Œæ··åˆè°ƒä¼˜æ•ˆæœæ›´å¥½ã€‚ æ­¤å¤–ï¼Œæ··åˆè°ƒè°å…·æœ‰ä¸Dakwå’ŒMonz(2017)ä¸­çš„é›†æˆæ–¹æ³•ç±»ä¼¼çš„æ•ˆæœï¼Œä¸ä¼šé™ä½åŸŸå¤–è½¬æ¢æ€§èƒ½ã€‚</p>

<p>â€‹		æ­£åˆ™åŒ–Baroneç­‰äººã€‚ ï¼ˆ2017å¹´ï¼‰è¿˜è§£å†³äº†è°ƒè°æœŸé—´çš„è¿‡åº¦è°ƒè°é—®é¢˜ã€‚ ä»–ä»¬è§£å†³è¿™ä¸€é—®é¢˜çš„ç­–ç•¥æ˜¯æ¢ç´¢æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå¦‚è¾å­¦å’ŒL2æ­£åˆ™åŒ–ã€‚ æ­¤å¤–ï¼Œä»–ä»¬è¿˜æå‡ºè°ƒè°ï¼Œè¿™æ˜¯ä¸€ä¸ªå˜ä½“çš„é€€å‡ºï¼Œä»¥æ­£è§„åŒ–ã€‚ æˆ‘ä»¬è®¤ä¸ºæ··åˆè°ƒè°å’Œæ­£åˆ™åŒ–æŠ€æœ¯æ˜¯ç›¸è¾…ç›¸æˆçš„ã€‚</p>

<h3 id="422-architecture-centric">4.2.2 Architecture Centric</h3>

<p>â€‹		æœ¬èŠ‚ä¸­çš„æ–¹æ³•æ›´æ”¹NMTä½“ç³»ç»“æ„ä»¥é€‚åº”åŸŸã€‚</p>

<p>â€‹		æ·±åº¦èåˆä¸åŸŸå†…å•è¯­æ•°æ®è‡ªé€‚åº”çš„ä¸€ç§æŠ€æœ¯æ˜¯è®­ç»ƒç”¨äºNMTè§£ç å™¨çš„åŸŸå†…RNNLMï¼Œå¹¶å°†å…¶ä¸NMTæ¨¡å‹ç›¸ç»“åˆï¼ˆä¹Ÿç§°ä¸ºèåˆï¼‰(GÃ¼ulcco/Ehre et al.ï¼Œ2015ï¼‰ã€‚ èåˆå¯ä»¥æ˜¯æµ…çš„ï¼Œä¹Ÿå¯ä»¥æ˜¯æ·±çš„ã€‚ å½¢å¼ä¸Šï¼Œæ·±åº¦èåˆæŒ‡ç¤ºLMå’ŒNMTè¢«é›†æˆä¸ºå•ä¸ªè§£ç å™¨ï¼ˆå³ï¼Œå°†RNNLMé›†æˆåˆ°NMTæ¶æ„ä¸­ï¼‰ã€‚ æµ…èåˆè¡¨ç¤ºLMå’ŒNMTçš„åˆ†æ•°è¢«ä¸€èµ·è€ƒè™‘ï¼ˆå³ï¼Œç”¨RNNLMæ¨¡å‹é‡æ–°è®°å½•NMTæ¨¡å‹ï¼‰ã€‚
â€‹		åœ¨æ·±åº¦èåˆä¸­ï¼ŒRNNLMå’ŒNMTçš„è¯‘ç å™¨é€šè¿‡çº§è”å®ƒä»¬çš„éšè—çŠ¶æ€æ¥é›†æˆã€‚ åœ¨è®¡ç®—ä¸‹ä¸€ä¸ªå­—çš„è¾“å‡ºæ¦‚ç‡æ—¶ï¼Œæ¨¡å‹ä¼šè°ƒæ•´ä¸ºä½¿ç”¨RNNLMå’ŒNMTæ¨¡å‹çš„éšè—çŠ¶æ€ã€‚ Domhanå’ŒHieber(2017)æå‡ºäº†ä¸€ç§ä¸æ·±åº¦èšå˜æ–¹æ³•ç±»ä¼¼çš„æ–¹æ³•(GÃ¼ulccoverehreç­‰äººï¼Œ2015ï¼‰ã€‚ ç„¶è€Œï¼Œä¸åŒäºå•ç‹¬è®­ç»ƒRNNLMå’ŒNMTæ¨¡å‹(GÃ¼ulccoverehre et al.ï¼Œ2015ï¼‰ï¼ŒDomhanå’ŒHieber(2017)è”åˆè®­ç»ƒRNNLMå’ŒNMTæ¨¡å‹ã€‚</p>

<p>â€‹		åˆ©ç”¨å¤šé¢†åŸŸè¯­æ–™åº“ä¸­ä¿¡æ¯å¤šæ ·æ€§çš„é¢†åŸŸé‰´åˆ«å™¨ï¼ŒBritzç­‰äººã€‚ ï¼ˆ2017å¹´ï¼‰æå‡ºä¸€ç§åˆ¤åˆ«æ–¹æ³•ã€‚ åœ¨ä»–ä»¬çš„åˆ¤åˆ«æ–¹æ³•ä¸­ï¼Œä»–ä»¬åœ¨ç¼–ç å™¨çš„åŸºç¡€ä¸Šå¢åŠ äº†ä¸€ä¸ªå‰é¦ˆç½‘ç»œ(FFNN)ä½œä¸ºåˆ¤åˆ«å™¨ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æ¥é¢„æµ‹æºå¥å­çš„åŸŸã€‚ é‰´åˆ«å™¨ä¸NMTç½‘ç»œè”åˆä¼˜åŒ–ã€‚ å›¾7æ˜¾ç¤ºäº†è¯¥æ–¹æ³•çš„æ¦‚è¿°ã€‚</p>

<p>â€‹		åŸŸæ§åˆ¶é™¤äº†ä½¿ç”¨åŸŸä»¤ç‰Œæ¥æ§åˆ¶åŸŸä¹‹å¤–ï¼ŒKobusç­‰äººã€‚ ï¼ˆ2016ï¼‰æå‡ºåœ¨NMTçš„åµŒå…¥å±‚æ·»åŠ è¯çº§ç‰¹å¾æ¥æ§åˆ¶åŸŸã€‚ ç‰¹åˆ«æ˜¯ï¼Œä»–ä»¬ç»™æ¯ä¸ªå•è¯é™„åŠ äº†ä¸€ä¸ªåŸŸæ ‡è®°ã€‚ ä»–ä»¬è¿˜æå‡ºäº†ä¸€ç§åŸºäºæœ¯è¯­é¢‘ç‡-é€†æ–‡æ¡£é¢‘ç‡ï¼ˆtf-idfï¼‰çš„æ–¹æ³•æ¥é¢„æµ‹è¾“å…¥å¥å­çš„åŸŸæ ‡è®°ã€‚</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716145507.png" alt="image-20200716145014990" /></p>

<h3 id="423-decoding-centric">4.2.3 Decoding Centric</h3>

<p>â€‹		ä»¥è¯‘ç ä¸ºä¸­å¿ƒçš„æ–¹æ³•å…³æ³¨äºåŸŸè‡ªé€‚åº”è¯‘ç ç®—æ³•ï¼Œä¸å…¶ä»–ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯äº’è¡¥çš„ã€‚</p>

<p>â€‹		æµ…èåˆæµ…èåˆæ˜¯ä¸€ç§åœ¨å¤§å‹å•è¯­è¯­æ–™åº“ä¸Šè®­ç»ƒLMï¼Œç„¶åå°†å®ƒä»¬ä¸å…ˆå‰è®­ç»ƒè¿‡çš„NMTæ¨¡å‹ç›¸ç»“åˆçš„æ–¹æ³•(GÃ¼ulccoverehre et al.ï¼Œ2015ï¼‰ã€‚ åœ¨æµ…èåˆ(GÃ¼ulccoehre et al.ï¼Œ2015ï¼‰ä¸­ï¼ŒNMTæ¨¡å‹ç”Ÿæˆçš„ä¸‹ä¸€ä¸ªå•è¯å‡è®¾ç”±NMTå’ŒRNNLMæ¦‚ç‡çš„åŠ æƒå’Œé‡æ–°ç¼–ç ï¼ˆå›¾8ï¼‰ã€‚</p>

<p>â€‹		é›†æˆFreitagå’ŒAl-Onaizan(2016)æå‡ºé›†æˆåŸŸå¤–æ¨¡å‹å’Œè°ƒæ•´åçš„åŸŸå†…æ¨¡å‹ã€‚ ä»–ä»¬çš„åŠ¨æœºä¸Dakwaleå’ŒMonz(2017)çš„å·¥ä½œå®Œå…¨ç›¸åŒï¼Œå³é˜²æ­¢åŸŸå†…æ•°æ®è°ƒä¼˜åçš„åŸŸå¤–è½¬æ¢é€€åŒ–ã€‚</p>

<p>â€‹		ç¥ç»æ ¼æœç´¢ã€‚ ï¼ˆ2017ï¼‰æå‡ºäº†ä¸€ç§åŸºäºå †æ ˆçš„å­—æ ¼è§£ç ç®—æ³•ï¼Œè€Œå­—æ ¼æ˜¯ç”±SMTç”Ÿæˆçš„ï¼ˆDyer et al.ï¼Œ2008ï¼‰ã€‚ åœ¨ä»–ä»¬çš„åŸŸè‡ªé€‚åº”å®éªŒä¸­ï¼Œä»–ä»¬è¡¨æ˜åŸºäºå †æ ˆçš„è¯‘ç æ¯”å¸¸è§„è¯‘ç è¦å¥½ã€‚</p>

<h1 id="5-domain-adaptation-in-real-world-scenarios">5 Domain Adaptation in Real-World Scenarios</h1>

<p>â€‹		éœ€è¦æ ¹æ®ç‰¹å®šçš„åœºæ™¯é‡‡ç”¨é¢†åŸŸè‡ªé€‚åº”æ–¹æ³•ã€‚ ä¾‹å¦‚ï¼Œå½“åŸŸå¤–æ•°æ®ä¸­å­˜åœ¨ä¸€äº›ä¼ªå¹¶è¡Œçš„åŸŸå†…æ•°æ®æ—¶ï¼Œé¦–é€‰é€‰å¥ï¼› å½“åªæœ‰é¢å¤–çš„å•è¯­æ•°æ®æ—¶ï¼Œå¯ä»¥é‡‡ç”¨LMå’ŒNMTèåˆã€‚ åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼ŒåŸŸå¤–å¹¶è¡Œæ•°æ®å’Œå•è¯­åŸŸå†…æ•°æ®éƒ½å¯ç”¨ï¼Œä½¿å¾—ä¸åŒæ–¹æ³•çš„ç»„åˆæˆä¸ºå¯èƒ½ã€‚ Chuç­‰äººã€‚ ï¼ˆ2018å¹´ï¼‰å¼€å±•ä¸€é¡¹ç ”ç©¶ï¼Œå°†æ··åˆè°ƒè°ï¼ˆChuç­‰äººï¼Œ2017å¹´ï¼‰åº”ç”¨äºåˆæˆå¹¶è¡Œæ•°æ®ï¼ˆSennrichç­‰äººï¼Œ2016b)ï¼Œè¯¥ç ”ç©¶æ˜¾ç¤ºå‡ºæ¯”ä»»ä½•ä¸€ç§æ–¹æ³•éƒ½æ›´å¥½çš„æ€§èƒ½ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­ä¸æ¨èä»»ä½•ç‰¹å®šçš„æŠ€æœ¯ï¼Œè€Œæ˜¯å»ºè®®è¯»è€…ä¸ºè‡ªå·±çš„åœºæ™¯é€‰æ‹©æœ€å¥½çš„æ–¹æ³•ã€‚</p>

<p>â€‹		ä¸Šè¿°é¢†åŸŸè‡ªé€‚åº”ç ”ç©¶å¤§å¤šå‡è®¾æ•°æ®çš„é¢†åŸŸæ˜¯ç»™å®šçš„ã€‚ ç„¶è€Œï¼Œåœ¨è¯¸å¦‚åœ¨çº¿ç¿»è¯‘å¼•æ“ä¹‹ç±»çš„å®ç”¨è§†å›¾ä¸­ï¼Œç”¨æˆ·è¾“å…¥çš„å¥å­çš„åŸŸå¹¶æ²¡æœ‰ç»™å‡ºã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé¢„æµ‹è¾“å…¥å¥å­çš„åŸŸå¯¹äºè‰¯å¥½çš„ç¿»è¯‘æ˜¯è‡³å…³é‡è¦çš„ã€‚ ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒSMTä¸­çš„ä¸€ç§å¸¸ç”¨æ–¹æ³•æ˜¯å¯¹é¢†åŸŸè¿›è¡Œé«˜æˆæœ¬çš„åˆ†ç±»ï¼Œç„¶åä½¿ç”¨ç›¸åº”çš„æ¨¡å‹åœ¨åˆ†ç±»é¢†åŸŸä¸­ç¿»è¯‘è¾“å…¥å¥å­ï¼ˆHuckç­‰äººï¼Œ2015ï¼‰ã€‚ Xuç­‰äººã€‚ ï¼ˆ2007ï¼‰ä¸ºæ±‰è‹±ç¿»è¯‘ä»»åŠ¡è¿›è¡Œé¢†åŸŸåˆ†ç±»ã€‚ åˆ†ç±»å™¨ä½¿ç”¨LMæ’å€¼å’Œè¯æ±‡ç›¸ä¼¼æ€§ï¼Œå¯¹æ•´ä¸ªæ–‡æ¡£è¿›è¡Œæ“ä½œï¼Œè€Œä¸æ˜¯å¯¹å•ä¸ªå¥å­è¿›è¡Œæ“ä½œã€‚ å“ˆå…‹ç­‰äººã€‚ ï¼ˆ2015ï¼‰æ‰©å±•äº†Xuç­‰äººçš„å·¥ä½œã€‚ ï¼ˆ2007å¹´ï¼‰ã€‚ å®ƒä»¬ä½¿ç”¨LMså’Œæœ€å¤§ç†µåˆ†ç±»å™¨æ¥é¢„æµ‹ç›®æ ‡åŸŸã€‚ Banerjeeç­‰äººã€‚ ï¼ˆ2010ï¼‰ä½¿ç”¨tf-idfç‰¹å¾æ„å»ºæ”¯æŒå‘é‡æœºåˆ†ç±»å™¨ã€‚ åˆ†ç±»æ˜¯åœ¨å•ä¸ªå¥å­çš„æ°´å¹³ä¸Šè¿›è¡Œçš„ã€‚ Wangç­‰äººã€‚ ï¼ˆ2012ï¼‰ä¾èµ–äºå…·æœ‰å„ç§åŸºäºçŸ­è¯­çš„ç‰¹å¾çš„å¹³å‡æ„ŸçŸ¥å™¨åˆ†ç±»å™¨ã€‚</p>

<p>â€‹		å¯¹äºNMTï¼ŒKobusç­‰äººã€‚ ï¼ˆ2016ï¼‰æå‡ºäº†ä¸€ç§NMTåŸŸæ§åˆ¶æ–¹æ³•ï¼Œé€šè¿‡åœ¨NMTçš„è¯åµŒå…¥å±‚æ·»åŠ åŸŸæ ‡ç­¾æˆ–ç‰¹å¾ã€‚ å®ƒä»¬é‡‡ç”¨å†…éƒ¨åˆ†ç±»å™¨æ¥åŒºåˆ†åŸŸä¿¡æ¯ã€‚ Liç­‰äººã€‚ ï¼ˆ2016ï¼‰å»ºè®®ä½¿ç”¨æµ‹è¯•è¯­å¥ä½œä¸ºæŸ¥è¯¢åœ¨è®­ç»ƒæ•°æ®ä¸­æœç´¢ç›¸ä¼¼è¯­å¥ï¼Œç„¶åä½¿ç”¨æ£€ç´¢åˆ°çš„è®­ç»ƒè¯­å¥è°ƒæ•´NMTæ¨¡å‹ä»¥ç¿»è¯‘æµ‹è¯•è¯­å¥ã€‚ Farajianç­‰äººã€‚ ï¼ˆ2017ï¼‰éµå¾ªLiç­‰äººçš„ç­–ç•¥ã€‚ ï¼ˆ2016ï¼‰ï¼Œä½†æå‡ºåŸºäºè¾“å…¥å¥å­å’Œæ£€ç´¢åˆ°çš„å¥å­çš„ç›¸ä¼¼åº¦åŠ¨æ€è®¾ç½®å­¦ä¹ ç®—æ³•çš„è¶…å‚æ•°ï¼ˆå³å­¦ä¹ é€Ÿç‡å’Œå†å…ƒæ•°ï¼‰ï¼Œç”¨äºæ›´æ–°NMTæ¨¡å‹ã€‚ å›¾9æ˜¾ç¤ºäº†è¾“å…¥åŸŸæœªçŸ¥åœºæ™¯ä¸­MTçš„åŸŸé€‚é…çš„æ¦‚è¿°ã€‚</p>

<p><img src="https://cdn.jsdelivr.net/gh/tian-guo-guo/cdn@master/assets/picgoimg/20200716145037.png" alt="image-20200716145037266" /></p>

<h1 id="6-future-directions">6 Future Directions</h1>

<h2 id="61-domain-adaptation-for-state-of-art-nmt-architectures">6.1 Domain Adaptation for State-of-art NMT Architectures</h2>

<p>â€‹		è‡ªä»åŸºäºRNNçš„NMTçš„æˆåŠŸï¼ˆCho et al.ï¼Œ2014ï¼›Sutskever et al.ï¼Œ2014ï¼›Bahdanau et al.ï¼Œ2015ï¼‰ä»¥æ¥ï¼ŒNMTçš„å…¶ä»–æ¶æ„å·²ç»è¢«å¼€å‘ã€‚ ä¸€ä¸ªä»£è¡¨æ€§çš„æ¶æ„æ˜¯åŸºäºCNNçš„NMTï¼ˆGehringç­‰äººï¼Œ2017ï¼‰ã€‚ ä¸åŸºäºRNNçš„æ¨¡å‹ç›¸æ¯”ï¼ŒåŸºäºCNNçš„æ¨¡å‹å¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®Œå…¨å¹¶è¡Œè®¡ç®—ï¼Œå¹¶ä¸”æ›´æ˜“äºä¼˜åŒ–ã€‚ å¦ä¸€ä¸ªä»£è¡¨æ€§çš„æ¶æ„æ˜¯Transformerï¼Œå®ƒä»…åŸºäºæ³¨æ„åŠ›ï¼ˆVaswaniç­‰äººï¼Œ2017ï¼‰ã€‚ ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäºCNNçš„NMTå’Œå˜å‹å™¨çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºWuç­‰äººçš„åŸºäºRNNçš„NMTæ¨¡å‹ã€‚ ï¼ˆ2016å¹´ï¼‰åœ¨ç¿»è¯‘è´¨é‡å’Œé€Ÿåº¦ä¸¤ä¸ªæ–¹é¢ã€‚ ç„¶è€Œï¼Œç›®å‰å¤§å¤šæ•°é’ˆå¯¹NMTçš„åŸŸé€‚åº”ç ”ç©¶éƒ½æ˜¯åŸºäºRNNæ¨¡å‹ï¼ˆBahdanauç­‰äººï¼Œ2015ï¼‰ã€‚ é’ˆå¯¹è¿™äº›æœ€æ–°çš„NMTæ¨¡å‹çš„åŸŸè‡ªé€‚åº”æŠ€æœ¯çš„ç ”ç©¶æ˜¾ç„¶æ˜¯æœªæ¥çš„ä¸€ä¸ªé‡è¦æ–¹å‘ã€‚</p>

<h2 id="62-domain-specific-dictionary-incorporation">6.2 Domain Specific Dictionary Incorporation</h2>

<p>â€‹		å¦‚ä½•åˆ©ç”¨è¯å…¸ï¼ŒçŸ¥è¯†åº“ç­‰å¤–éƒ¨çŸ¥è¯†è¿›è¡Œå¤–è¯­æ•™å­¦æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ç ”ç©¶é—®é¢˜ã€‚ åœ¨é¢†åŸŸé€‚é…ä¸­ï¼Œä½¿ç”¨é¢†åŸŸè§„èŒƒè¯å…¸æ˜¯ä¸€ä¸ªéå¸¸å…³é”®çš„é—®é¢˜ã€‚ ä»å®è·µçš„è§’åº¦æ¥çœ‹ï¼Œè®¸å¤šç¿»è¯‘å…¬å¸å·²ç»åˆ›å»ºäº†é¢†åŸŸè§„èŒƒè¯å…¸ï¼Œä½†æ²¡æœ‰åˆ›å»ºé¢†åŸŸè§„èŒƒè¯­æ–™åº“ã€‚ å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿç ”ç©¶ä¸€ç§ä½¿ç”¨é¢†åŸŸè§„èŒƒè¯å…¸çš„å¥½æ–¹æ³•ï¼Œå°†ä¼šæå¤§åœ°ä¿ƒè¿›MTçš„å®é™…åº”ç”¨ã€‚ æœ‰ä¸€äº›ç ”ç©¶å°è¯•ä½¿ç”¨è¯å…¸è¿›è¡ŒNMTï¼Œä½†å…¶ç”¨æ³•ä»…é™äºå¸®åŠ©ä½é¢‘åº¦æˆ–ç½•è§è¯çš„ç¿»è¯‘ï¼ˆArthur et al.ï¼Œ2016ï¼›Zhang and Zongï¼Œ2016a)ã€‚ Arcanå’ŒBuitelaar(2017)ä½¿ç”¨é¢†åŸŸè§„èŒƒè¯å…¸è¿›è¡Œæœ¯è¯­ç¿»è¯‘ï¼Œä½†å®ƒä»¬åªæ˜¯åº”ç”¨äº†Luongç­‰äººæå‡ºçš„æœªçŸ¥è¯æ›¿æ¢æ–¹æ³•ã€‚ ï¼ˆ2015å¹´ï¼‰ï¼Œå®ƒé­å—å˜ˆæ‚çš„å…³æ³¨ã€‚</p>

<h2 id="63-multilingual-and-multi-domain-adaptation">6.3 Multilingual and Multi-Domain Adaptation</h2>

<p>â€‹		åœ¨åŒä¸€è¯­è¨€å¯¹ä¸­ä½¿ç”¨åŸŸå¤–å¹³è¡Œè¯­æ–™åº“å¯èƒ½å¹¶ä¸æ€»æ˜¯å¯èƒ½çš„ï¼Œå› æ­¤ä½¿ç”¨å…¶ä»–è¯­è¨€çš„æ•°æ®å¾ˆé‡è¦ï¼ˆJohnson et al.ï¼Œ2016ï¼‰ã€‚ è¿™ç§å­¦ä¹ æ–¹æ³•è¢«ç§°ä¸ºè·¨è¯­è¿ç§»å­¦ä¹ ï¼Œå³åœ¨å¤šç§è¯­è¨€ä¹‹é—´ä¼ é€’NMTæ¨¡å‹å‚æ•°ã€‚ å¤šè¯­è¨€æ¨¡å‹ä¾èµ–äºå‚æ•°å…±äº«ï¼Œæœ‰åŠ©äºæé«˜ä½èµ„æºè¯­è¨€çš„ç¿»è¯‘è´¨é‡ï¼Œå°¤å…¶æ˜¯åœ¨ç›®æ ‡è¯­è¨€ç›¸åŒçš„æƒ…å†µä¸‹ï¼ˆZoph et al.ï¼Œ2016ï¼‰ã€‚ æœ‰ä¸€äº›ç ”ç©¶è®­ç»ƒäº†å¤šè¯­è¨€ï¼ˆFirat et al.ï¼Œ2016ï¼›Johnson et al.ï¼Œ2017ï¼‰æˆ–å¤šåŸŸæ¨¡å‹ï¼ˆSajjad et al.ï¼Œ2017ï¼‰ï¼Œä½†æ²¡æœ‰ä¸€ä¸ªç ”ç©¶è¯•å›¾å°†å¤šä¸ªè¯­è¨€å¯¹å’Œå¤šä¸ªåŸŸæ‰“åŒ…æˆä¸€ä¸ªå•ä¸€çš„ç¿»è¯‘ç³»ç»Ÿã€‚ å³ä½¿å­˜åœ¨åŒä¸€è¯­è¨€å¯¹ä¸­çš„åŸŸå¤–æ•°æ®ï¼ŒåŒæ—¶ä½¿ç”¨å¤šè¯­è¨€å’Œå¤šåŸŸæ•°æ®ä¹Ÿæœ‰å¯èƒ½æé«˜ç¿»è¯‘æ€§èƒ½ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬è®¤ä¸ºé’ˆå¯¹NMTçš„å¤šè¯­è¨€ï¼Œå¤šé¢†åŸŸé€‚é…å¯ä»¥æ˜¯æœªæ¥çš„å¦ä¸€ä¸ªæ–¹å‘ã€‚ Chuå’ŒDabreï¼ˆ2018ï¼‰é’ˆå¯¹è¿™ä¸€è¯¾é¢˜è¿›è¡Œäº†åˆæ­¥ç ”ç©¶ã€‚</p>

<h2 id="64-adversarial-domain-adaptation-and-domain-generation">6.4 Adversarial Domain Adaptation and Domain Generation</h2>

<p>â€‹		ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ˜¯ä¸€ç±»ç”¨äºæ— ç›‘ç£æœºå™¨å­¦ä¹ çš„äººå·¥æ™ºèƒ½ç®—æ³•ï¼Œç”±Goodfellowç­‰äººï¼ˆ2014ï¼‰æå‡ºã€‚ å¯¹æŠ—æ€§æ–¹æ³•å·²ç»åœ¨åŸŸè‡ªé€‚åº”ä¸­å˜å¾—æµè¡Œï¼ˆGaninç­‰äººï¼Œ2016ï¼‰ï¼Œå…¶é€šè¿‡ç›¸å¯¹äºåŸŸé‰´åˆ«å™¨çš„å¯¹æŠ—æ€§ç›®æ ‡æœ€å°åŒ–è¿‘ä¼¼åŸŸå·®å¼‚è·ç¦»ï¼ˆTzengç­‰äººï¼Œ2017ï¼‰ã€‚ å®ƒä»¬å·²è¢«åº”ç”¨äºè®¡ç®—æœºè§†è§‰å’Œæœºå™¨å­¦ä¹ ä¸­çš„é¢†åŸŸè‡ªé€‚åº”ä»»åŠ¡ï¼ˆTzeng et al.ï¼Œ2017ï¼›Motiian et al.ï¼Œ2017ï¼›Volpi et al.ï¼Œ2017ï¼›Zhao et al.ï¼Œ2017ï¼›Pei et al.ï¼Œ2018ï¼‰ã€‚ æœ€è¿‘ï¼Œä¸€äº›å¯¹æŠ—æ–¹æ³•å¼€å§‹è¢«å¼•å…¥åˆ°ä¸€äº›NLPä»»åŠ¡ï¼ˆLiu et al.ï¼Œ2017ï¼›Chen et al.ï¼Œ2017b)å’ŒNMTï¼ˆBritz et al.ï¼Œ2017ï¼‰ä¸­ã€‚</p>

<p>â€‹		ç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•ä¾§é‡äºä»é€šç”¨åŸŸåˆ°ç‰¹å®šåŸŸçš„é€‚åº”ã€‚ åœ¨å®é™…åœºæ™¯ä¸­ï¼Œè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®å…·æœ‰ä¸åŒçš„åˆ†å¸ƒï¼Œç›®æ ‡åŸŸæœ‰æ—¶æ˜¯çœ‹ä¸åˆ°çš„ã€‚ æ¬§æ–‡ç­‰äººã€‚ ï¼ˆ2013ï¼‰åˆ†ææ­¤ç±»æƒ…æ™¯ä¸‹çš„ç¿»è¯‘é”™è¯¯ã€‚ é¢†åŸŸæ³›åŒ–æ—¨åœ¨å°†ä»æ ‡è®°çš„æºé¢†åŸŸè·å¾—çš„çŸ¥è¯†åº”ç”¨åˆ°çœ‹ä¸è§çš„ç›®æ ‡é¢†åŸŸï¼ˆLi et al.ï¼Œ2018ï¼‰ã€‚ å®ƒæä¾›äº†ä¸€ç§åœ¨çœŸå®ä¸–ç•ŒMTä¸­åŒ¹é…è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®åˆ†å¸ƒçš„æ–¹å¼ï¼Œè¿™å¯èƒ½æ˜¯NMTé¢†åŸŸé€‚é…çš„ä¸€ä¸ªæœªæ¥è¶‹åŠ¿ã€‚</p>

<h1 id="7-conclusion">7 Conclusion</h1>

<p>â€‹		NMTé¢†åŸŸé€‚é…æ˜¯ä¸€ä¸ªè¾ƒæ–°ä½†åˆéå¸¸é‡è¦çš„ç ”ç©¶è¯¾é¢˜ï¼Œä»¥ä¿ƒè¿›MTå®ç”¨åŒ–ã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¯¹ä¸»è¦åœ¨è¿‡å»ä¸¤å¹´ä¸­å¼€å‘çš„æŠ€æœ¯è¿›è¡Œäº†é¦–æ¬¡å…¨é¢çš„å›é¡¾ã€‚ æœ¬æ–‡æ¯”è¾ƒäº†NMTçš„åŸŸé€‚é…æŠ€æœ¯å’ŒSMTçš„åŸŸé€‚é…æŠ€æœ¯ï¼Œåè€…æ˜¯è¿‘äºŒåå¹´æ¥çš„ä¸»è¦ç ”ç©¶é¢†åŸŸã€‚ æ­¤å¤–ï¼Œå±•æœ›äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚ å°†NMTä¸­çš„é¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯ä¸ä¸€èˆ¬çš„NLPï¼Œè®¡ç®—æœºè§†è§‰å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯ç›¸ç»“åˆæ˜¯æˆ‘ä»¬ä»Šåçš„å·¥ä½œã€‚ æˆ‘ä»¬å¸Œæœ›è¿™ç¯‡è°ƒæŸ¥è®ºæ–‡èƒ½å¤Ÿå¯¹NMTé¢†åŸŸé€‚é…çš„ç ”ç©¶èµ·åˆ°é‡è¦çš„æ¨åŠ¨ä½œç”¨ã€‚</p>

<h1 id="8-references">8 References</h1>

<p>Mihael Arcan and Paul Buitelaar. 2017. Translating domain-speciï¬c expressions in knowledge bases with neural machine translation. CoRR, abs/1709.02184.</p>

<p>Philip Arthur, Graham Neubig, and Satoshi Nakamura. 2016. Incorporating discrete translation lexicons into neural machine translation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1557â€“1567, Austin, Texas, November. Association for Computational Linguistics.</p>

<p>Amittai Axelrod, Xiaodong He, and Jianfeng Gao. 2011. Domain adaptation via pseudo in-domain data selection.</p>

<p>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 355â€“362, Edinburgh, Scotland, U.K.</p>

<p>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In In Proceedings of the 3rd International Conference on Learning Representations (ICLR 2015), San Diego, USA, May. International Conference on Learning Representations.</p>

<p>Pratyush Banerjee, Jinhua Du, Baoli Li, Sudip Naskar, Andy Way, and Josef Genabith. 2010. Combining multidomain statistical machine translation models using automatic classiï¬ers. In The Ninth Conference of the Association for Machine Translation in the Americas, Denver, Colorado.</p>

<p>Arianna Bisazza, Nick Ruiz, and Marcello Federico. 2011. Fill-up versus interpolation methods for phrase-based SMT adaptation. In IWSLT, pages 136â€“143. ISCA.</p>

<p>OndË‡rej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Shujian Huang, Matthias Huck, Philipp Koehn, Qun Liu, Varvara Logacheva, Christof Monz, Matteo Negri, Matt Post, Raphael Rubino, Lucia Specia, and Marco Turchi. 2017. Findings of the 2017 conference on machine translation (WMT17). In Proceedings of the Second Conference on Machine Translation, pages 169â€“214, Copenhagen, Denmark, September. Association for Computational Linguistics.</p>

<p>Denny Britz, Quoc Le, and Reid Pryzant. 2017. Effective domain mixing for neural machine translation. In Proceedings of the Second Conference on Machine Translation, pages 118â€“126, Copenhagen, Denmark, September. Association for Computational Linguistics.</p>

<p>M Cettolo, J Niehues, S StÂ¨uker, L Bentivogli, R Cattoni, and M Federico. 2015. The iwslt 2015 evaluation campaign. In Proceedings of the Twelfth International Workshop on Spoken Language Translation (IWSLT).</p>

<p>Boxing Chen, Roland Kuhn, George Foster, Colin Cherry, and Fei Huang. 2016. Bilingual methods for adaptive training data selection for machine translation. In The Twelfth Conference of The Association for Machine Translation in the Americas, pages 93â€“106, Austin, Texas.</p>

<p>Boxing Chen, Colin Cherry, George Foster, and Samuel Larkin. 2017a. Cost weighting for neural machine translation domain adaptation. In Proceedings of the First Workshop on Neural Machine Translation, pages 40â€“46, Vancouver.</p>

<p>Xinchi Chen, Zhan Shi, Xipeng Qiu, and Xuanjing Huang. 2017b. Adversarial multi-criteria learning for chinese word segmentation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1193â€“1203, Vancouver, Canada. Association for Computational Linguistics.</p>

<p>Yong Cheng, Wei Xu, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu. 2016. Semi-supervised learning for neural machine translation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1965â€“1974, Berlin, Germany, August. Association for Computational Linguistics.</p>

<p>Kyunghyun Cho, Bart van MerriÂ¨enboer, CÂ¸alar GÂ¨ulcÂ¸ehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using rnn encoderâ€“decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1724â€“1734, Doha, Qatar, October. Association for Computational Linguistics.</p>

<p>Chenhui Chu and Raj Dabre. 2018. Multilingual and multi-domain adaptation for neural machine translation. In Proceedings of the 24st Annual Meeting of the Association for Natural Language Processing (NLP 2018), pages 909â€“912, Okayama, Japan, Match.</p>

<p>Chenhui Chu, Raj Dabre, and Sadao Kurohashi. 2017. An empirical comparison of domain adaptation methods for neural machine translation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Vancouver, Canada, July. Association for Computational Linguistics.</p>

<p>Chenhui Chu, Raj Dabre, and Sadao Kurohashi. 2018. A comprehensive empirical comparison of domain adaptation methods for neural machine translation. Journal of Information Processing (JIP), 26(1):1â€“10.</p>

<p>Chenhui Chu. 2015. Integrated parallel data extraction from comparable corpora for statistical machine translation. Doctoral Thesis, Kyoto University.</p>

<p>Gabriela Csurka.</p>

<p>2017.</p>

<p>Domain adaptation for visual applications:</p>

<p>A comprehensive survey.</p>

<p>CoRR,</p>

<p>abs/1702.05374.</p>

<p>Anna Currey, Antonio Valerio Miceli Barone, and Kenneth Heaï¬eld. 2017. Copied monolingual data improves low-resource neural machine translation. In Proceedings of the Second Conference on Machine Translation, pages 148â€“156, Copenhagen, Denmark, September. Association for Computational Linguistics.</p>

<p>Praveen Dakwale and Christof Monz. 2017. Fine-tuning for neural machine translation with limited degradation across in- and out-of-domain data. In Proceedings of the 16th Machine Translation Summit (MT-Summit 2017), pages 156â€“169.</p>

<p>Tobias Domhan and Felix Hieber. 2017. Using target-side monolingual data for neural machine translation through multi-task learning. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1500â€“1505, Copenhagen, Denmark, September. Association for Computational Linguistics.</p>

<p>Kevin Duh, Graham Neubig, Katsuhito Sudoh, and Hajime Tsukada. 2013. Adaptation data selection using neural language models: Experiments in machine translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 678â€“683, Soï¬a, Bulgaria, August.</p>

<p>Nadir Durrani, Hassan Sajjad, Shaï¬q Joty, Ahmed Abdelali, and Stephan Vogel. 2015. Using joint models for domain adaptation in statistical machine translation. In Proceedings of MT Summit XV, pages 117â€“130, Miami, FL, USA.</p>

<p>Christopher Dyer, Smaranda Muresan, and Philip Resnik. 2008. Generalizing word lattice translation. In Proceedings of ACL-08: HLT, pages 1012â€“1020, Columbus, Ohio, June. Association for Computational Linguistics.</p>

<p>M. Amin Farajian, Marco Turchi, Matteo Negri, and Marcello Federico. 2017. Multi-domain neural machine translation through unsupervised adaptation. In Proceedings of the Second Conference on Machine Translation, pages 127â€“137, Copenhagen, Denmark, September. Association for Computational Linguistics.</p>

<p>Orhan Firat, Kyunghyun Cho, and Yoshua Bengio. 2016. Multi-way, multilingual neural machine translation with a shared attention mechanism. In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016, pages 866â€“875.</p>

<p>George Foster and Roland Kuhn. 2007. Mixture-model adaptation for smt. In Proceedings of the Second Workshop on Statistical Machine Translation, StatMT â€™07, pages 128â€“135, Stroudsburg, PA, USA. Association for Computational Linguistics.</p>

<p>George Foster, Cyril Goutte, and Roland Kuhn. 2010. Discriminative instance weighting for domain adaptation in statistical machine translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 451â€“459, Cambridge, MA.</p>

<p>Markus Freitag and Yaser Al-Onaizan.</p>

<p>2016.</p>

<p>Fast domain adaptation for neural machine translation. arXiv</p>

<p>preprint arXiv:1612.06897.</p>

<p>Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FrancÂ¸ois Laviolette, Mario Marchand, and Victor Lempitsky. 2016. Domain-adversarial training of neural networks. Journal of Machine Learning Research, 17(59):1â€“35.</p>

<p>Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. 2017. Convolutional sequence to sequence learning. CoRR, abs/1705.03122.</p>

<p>Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in neural information processing systems, pages 2672â€“2680.</p>

<p>Isao Goto, Ka-Po Chow, Bin Lu, Eiichiro Sumita, and Benjamin K. Tsou. 2013. Overview of the patent machine translation task at the ntcir-10 workshop. In Proceedings of the 10th NTCIR Conference, pages 260â€“286, Tokyo, Japan, June. National Institute of Informatics (NII).</p>

<p>CÂ¸aglar GÂ¨ulcÂ¸ehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho, LoÂ¨Ä±c Barrault, Huei-Chi Lin, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2015. On using monolingual corpora in neural machine translation. CoRR, abs/1503.03535.</p>

<p>Geoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. 2015. Distilling the knowledge in a neural network. In NIPS Deep Learning and Representation Learning Workshop.</p>

<p>Cuong Hoang and Khalil Simaâ€™an. 2014. Latent domain translation models in mix-of-domains haystack. In Proceedings of the 25th International Conference on Computational Linguistics: Technical Papers, pages 19281939, Dublin, Ireland.</p>

<p>Matthias Huck, Alexandra Birch, and Barry Haddow. 2015. Mixed-domain vs. multi-domain statistical machine translation. Proceedings of MT Summit XV, 1:240â€“255.</p>

<p>Kenji Imamura and Eiichiro Sumita. 2016. Multi-domain adaptation for statistical machine translation based on feature augmentation. In Proceedings of the 12th Conference of the Association for Machine Translation in the Americas, Austin, Texas, USA.</p>

<p>Ann Irvine, John Morgan, Marine Carpuat, Hal Daume III, and Dragos Munteanu. 2013. Measuring machine translation errors in new domains. Transactions of the Association for Computational Linguistics, 1:429â€“440. SÂ´ebastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2015. On using very large target vocabulary for neural machine translation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1â€“10, Beijing, China, July. Association for Computational Linguistics.</p>

<p>Jing Jiang and ChengXiang Zhai. 2007. Instance weighting for domain adaptation in NLP. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 264â€“271, Prague, Czech Republic. Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda B. ViÂ´egas, Martin Wattenberg, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016. Googleâ€™s multilingual neural machine translation system: Enabling zero-shot translation. CoRR, abs/1611.04558. Melvin Johnson, Mike Schuster, Quoc Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernand a Vigas, Martin Wattenberg, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2017. Googleâ€™s multilingual neural machine translation system: Enabling zero-shot translation. Transactions of the Association for Computational Linguistics, 5:339â€“351.</p>

<p>Huda Khayrallah, Gaurav Kumar, Kevin Duh, Matt Post, and Philipp Koehn. 2017. Neural lattice search for domain adaptation in machine translation. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 20â€“25, Taipei, Taiwan, November. Asian Federation of Natural Language Processing.</p>

<p>Catherine Kobus, Josep Crego, and Jean Senellart. 2016. Domain control for neural machine translation. arXiv preprint arXiv:1612.06140.</p>

<p>Philipp Koehn and Rebecca Knowles. 2017. Six challenges for neural machine translation. In Proceedings of the First Workshop on Neural Machine Translation, pages 28â€“39, Vancouver, August. Association for Computational Linguistics.</p>

<p>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177â€“180, Prague, Czech Republic, June. Association for Computational Linguistics. Philipp Koehn. 2017. Neural machine translation. CoRR, abs/1709.07809.</p>

<p>Patrik Lambert, Holger Schwenk, Christophe Servan, and Sadaf Abdul-Rauf. 2011. Investigations on translation model adaptation using monolingual data. In Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT â€™11, pages 284â€“293, Stroudsburg, PA, USA. Association for Computational Linguistics. Xiaoqing Li, Jiajun Zhang, and Chengqing Zong. 2016. One sentence one model for neural machine translation.</p>

<p>CoRR, abs/1609.06490.</p>

<p>Ya Li, Mingming Gong, Xinmei Tian, Tongliang Liu, and Dacheng Tao. 2018. Domain generalization via conditional invariant representations. In The Thirty-Second AAAI Conference on Artiï¬cial Intelligence.</p>

<p>Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2017. Adversarial multi-task learning for text classiï¬cation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1â€“10, Vancouver, Canada. Association for Computational Linguistics.</p>

<p>Minh-Thang Luong and Christopher D Manning. 2015. Stanford neural machine translation systems for spoken language domains. In Proceedings of the 12th International Workshop on Spoken Language Translation, pages 76â€“79, Da Nang, Vietnam, December.</p>

<p>Thang Luong, Ilya Sutskever, Quoc Le, Oriol Vinyals, and Wojciech Zaremba. 2015. Addressing the rare word problem in neural machine translation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 11â€“19, Beijing, China, July. Association for Computational Linguistics.</p>

<p>Saab Mansour and Hermann Ney. 2012. A simple and effective weighted phrase extraction for machine translation adaptation. In The 9th International Workshop on Spoken Language Translation, Hong Kong.</p>

<p>Benjamin Marie and Atsushi Fujita. 2017. Efï¬cient extraction of pseudo-parallel sentences from raw monolingual data using word embeddings. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 392â€“398, Vancouver, Canada, July. Association for Computational Linguistics.</p>

<p>Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing Zhang. 2009. Discriminative corpus weight estimation for machine translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 708â€“717, Singapore.</p>

<p>Antonio Valerio Miceli Barone, Barry Haddow, Ulrich Germann, and Rico Sennrich. 2017. Regularization techniques for ï¬ne-tuning in neural machine translation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1489â€“1494, Copenhagen, Denmark, September. Association for Computational Linguistics.</p>

<p>Robert C Moore and William Lewis. 2010. Intelligent selection of language model training data. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 220â€“224, Uppsala, Sweden.</p>

<p>Saeid Motiian, Quinn Jones, Seyed Mehdi Iranmanesh, and Gianfranco Doretto. 2017. Few-shot adversarial domain adaptation. CoRR, abs/1711.02536.</p>

<p>Toshiaki Nakazawa, Shohei Higashiyama, Chenchen Ding, Hideya Mino, Isao Goto, Hideto Kazawa, Yusuke Oda, Graham Neubig, and Sadao Kurohashi. 2017. Overview of the 4th workshop on asian translation. In Proceedings of the 4th Workshop on Asian Translation (WAT2017), pages 1â€“54, Taipei, Taiwan, November. Asian Federation of Natural Language Processing.</p>

<p>Graham Neubig. 2017. Neural machine translation and sequence-to-sequence models: A tutorial. CoRR, abs/1703.01619.</p>

<p>Jan Niehues and Alex H. Waibel. 2012. Detailed analysis of different strategies for phrase table adaptation in smt. In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA), San Diego, US-CA.</p>

<p>Sinno Jialin Pan and Qiang Yang. 2010. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering, 22(10):1345â€“1359, October.</p>

<p>Jaehong Park, Jongyoon Song, and Sungroh Yoon. 2017. Building a neural machine translation system using only synthetic parallel data. CoRR, abs/1704.00253.</p>

<p>Zhongyi Pei, Zhangjie Cao, Mingsheng Long, and Jianmin Wang. 2018. Multi-adversarial domain adaptation. Anthony Rousseau, Fethi Bougares, Paul DelÂ´eglise, Holger Schwenk, and Yannick Est`eve. 2011. Liums systems for the iwslt 2011 speech translation tasks. In International Workshop on Spoken Language Translation, San Francisco, USA.</p>

<p>Hassan Sajjad, Nadir Durrani, Fahim Dalvi, Yonatan Belinkov, and Stephan Vogel. 2017. Neural machine translation training in a multi-domain scenario. In Proceedings of the Twelfth International Workshop on Spoken Language Translation (IWSLT), Tokyo, Japan.</p>

<p>Rico Sennrich, Holger Schwenk, and Walid Aransa. 2013. A multi-domain translation model framework for statistical machine translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 832â€“840, Soï¬a, Bulgaria.</p>

<p>Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016a. Controlling politeness in neural machine translation via side constraints. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 35â€“40, San Diego, California, June. Association for Computational Linguistics.</p>

<p>Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016b. Improving neural machine translation models with monolingual data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 86â€“96, Berlin, Germany, August. Association for Computational Linguistics. Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016c. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715â€“1725, Berlin, Germany, August. Association for Computational Linguistics.</p>

<p>Christophe Servan, Josep Crego, and Jean Senellart. 2016. Domain specialization: a post-training domain adaptation for neural machine translation. arXiv preprint arXiv:1612.06141.</p>

<p>Kashif Shah, LoÂ¨Ä±c Barrault, and Holger Schwenk. 2010. Translation model adaptation by resampling. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 392â€“399. Kashif Shah, LoÂ¨Ä±c Barrault, and Holger Schwenk. 2012. A general framework to weight heterogeneous parallel data for model adaptation in statistical machine translation. In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA), San Diego, US-CA.</p>

<p>Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. In Proceedings of the 27th International Conference on Neural Information Processing Systems, pages 3104â€“3112, Cambridge, MA, USA. MIT Press.</p>

<p>Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. 2017. Adversarial discriminative domain adaptation.</p>

<p>CoRR, abs/1702.05464.</p>

<p>Masao Utiyama and Hitoshi Isahara. 2003. Reliable measures for aligning japanese-english news articles and sentences. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 72â€“79, Sapporo, Japan, July. Association for Computational Linguistics.</p>

<p>Marlies van der Wees, Arianna Bisazza, and Christof Monz. 2017. Dynamic data selection for neural machine translation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1400â€“1410, Copenhagen, Denmark, September. Association for Computational Linguistics.</p>

<p>Adam Csaba Varga. 2017. Domain adaptation for multilingual neural machine translation. Master Thesis, Saarlandes University.</p>

<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Å ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5998â€“6008. Curran Associates, Inc.</p>

<p>Riccardo Volpi, Pietro Morerio, Silvio Savarese, and Vittorio Murino. 2017. Adversarial feature augmentation for unsupervised domain adaptation. CoRR, abs/1711.08561.</p>

<p>Wei Wang, Klaus Macherey, Wolfgang Macherey, Franz Och, and Peng Xu. 2012. Improved domain adaptation for statistical machine translation. In Proceedings of AMTA, San Diego, California, USA.</p>

<p>Rui Wang, Hai Zhao, Bao-Liang Lu, Masao Utiyama, and Eiichiro Sumita. 2014. Neural network based bilingual language model growing for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 189â€“195, Doha, Qatar, October. Association for Computational Linguistics.</p>

<p>Rui Wang, Hai Zhao, Bao-Liang Lu, Masao Utiyama, and Eiichiro Sumita. 2016. Connecting phrase based statistical machine translation adaptation. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 3135â€“3145, Osaka, Japan, December. The COLING 2016 Organizing Committee.</p>

<p>Rui Wang, Andrew Finch, Masao Utiyama, and Eiichiro Sumita. 2017a. Sentence embedding for neural machine translation domain adaptation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 560â€“566, Vancouver, Canada, July. Association for Computational Linguistics.</p>

<p>Rui Wang, Masao Utiyama, Lemao Liu, Kehai Chen, and Eiichiro Sumita. 2017b. Instance weighting for neural machine translation domain adaptation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1482â€“1488, Copenhagen, Denmark.</p>

<p>Rui Wang, Masao Utiyama, Andrew Finch, Lemao Liu, Kehai Chen, and Eiichiro Sumita. 2018. Sentence selection and weighting for neural machine translation domain adaptation. IEEE/ACM Transactions on Audio, Speech, and Language Processing.</p>

<p>Karl Weiss, Taghi M. Khoshgoftaar, and DingDing Wang. 2016. A survey of transfer learning. Journal of Big Data, 3(1):9, May.</p>

<p>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016. Googleâ€™s neural machine translation system: Bridging the gap between human and machine translation. CoRR, abs/1609.08144.</p>

<p>Jia Xu, Yonggang Deng, Yuqing Gao, and Hermann Ney. 2007. Domain dependent statistical machine translation.</p>

<p>In MT Summit, Copenhagen, Denmark.</p>

<p>Jiajun Zhang and Chengqing Zong. 2016a. Bridging neural machine translation and bilingual dictionaries. CoRR, abs/1610.07272.</p>

<p>Jiajun Zhang and Chengqing Zong. 2016b. Exploiting source-side monolingual data in neural machine translation.</p>

<p>In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 15351545, Austin, Texas, November. Association for Computational Linguistics.</p>

<p>Han Zhao, Shanghang Zhang, Guanhang Wu, JoËœao P. Costeira, JosÂ´e M. F. Moura, and Geoffrey J. Gordon. 2017.</p>

<p>Multiple source domain adaptation with adversarial training of neural networks. CoRR, abs/1705.09684.</p>

<p>Xinpeng Zhou, Hailong Cao, and Tiejun Zhao. 2015. Domain adaptation for SMT using sentence weight. In Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data, pages 153â€“163, Guangzhou, China.</p>

<p>Barret Zoph, Deniz Yuret, Jonathan May, and Kevin Knight. 2016. Transfer learning for low-resource neural machine translation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, pages 1568â€“1575.</p>
:ET