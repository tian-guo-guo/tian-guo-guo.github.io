I"û3<h1 id="bertå‘½åå®ä½“è¯†åˆ«tensorflow">BERTå‘½åå®ä½“è¯†åˆ«TensorFlow</h1>

<h1 id="ä¸€åŸºäºæºç å®‰è£…">ä¸€ã€åŸºäºæºç å®‰è£…</h1>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/macanv/BERT-BiLSTM-CRF-NER
cd BERT-BiLSTM-CRF-NER/
python3 setup.py install
</code></pre></div></div>

<h1 id="äºŒä¸¤ä¸ªå‘½ä»¤è¡Œå·¥å…·bert-base-ner-train-åŸºäºå‘½åè¡Œè®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹">äºŒã€ä¸¤ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼šbert-base-ner-train åŸºäºå‘½åè¡Œè®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹</h1>

<p>å®‰è£…å®Œbert-baseåï¼Œä¼šç”Ÿæˆä¸¤ä¸ªåŸºäºå‘½åè¡Œçš„å·¥å…·ï¼Œå…¶ä¸­bert-base-ner-trainæ”¯æŒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒï¼Œä½ åªéœ€è¦æŒ‡å®šè®­ç»ƒæ•°æ®çš„ç›®å½•ï¼ŒBERTç›¸å…³å‚æ•°çš„ç›®å½•å³å¯ã€‚å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹å¸®åŠ©</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensorflow) root@e1fd7a8d1822:~/tian# bert-base-ner-train  -help
usage: bert-base-ner-train [-h] [-data_dir DATA_DIR]
                           [-bert_config_file BERT_CONFIG_FILE]
                           [-output_dir OUTPUT_DIR]
                           [-init_checkpoint INIT_CHECKPOINT]
                           [-vocab_file VOCAB_FILE]
                           [-max_seq_length MAX_SEQ_LENGTH] [-do_train]
                           [-do_eval] [-do_predict] [-batch_size BATCH_SIZE]
                           [-learning_rate LEARNING_RATE]
                           [-num_train_epochs NUM_TRAIN_EPOCHS]
                           [-dropout_rate DROPOUT_RATE] [-clip CLIP]
                           [-warmup_proportion WARMUP_PROPORTION]
                           [-lstm_size LSTM_SIZE] [-num_layers NUM_LAYERS]
                           [-cell CELL]
                           [-save_checkpoints_steps SAVE_CHECKPOINTS_STEPS]
                           [-save_summary_steps SAVE_SUMMARY_STEPS]
                           [-filter_adam_var FILTER_ADAM_VAR]
                           [-do_lower_case DO_LOWER_CASE] [-clean CLEAN]
                           [-device_map DEVICE_MAP] [-label_list LABEL_LIST]
                           [-verbose] [-ner NER] [-version]
bert-base-ner-train: error: argument -h/--help: ignored explicit argument 'elp'
</code></pre></div></div>

<p>è®­ç»ƒçš„äº‹ä¾‹å‘½åå¦‚ä¸‹ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-ner-train \
    -data_dir {your dataset dir}\
    -output_dir {training output dir}\
    -init_checkpoint {Google BERT model dir}\
    -bert_config_file {bert_config.json under the Google BERT model dir} \
    -vocab_file {vocab.txt under the Google BERT model dir}
</code></pre></div></div>

<ul>
  <li>
    <p>data_diræ˜¯ä½ çš„æ•°æ®æ‰€åœ¨çš„ç›®å½•ï¼Œè®­ç»ƒæ•°æ®ï¼ŒéªŒè¯æ•°æ®å’Œæµ‹è¯•æ•°æ®å‘½åæ ¼å¼ä¸ºï¼štrain.txt, dev.txtï¼Œtest.txt,è¯·æŒ‰ç…§è¿™ä¸ªæ ¼å¼å‘½åæ–‡ä»¶ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚<a href="https://blog.csdn.net/u010189459/article/details/38546115?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task">æ•°æ®æ ‡æ³¨ä»£ç å‚è€ƒ</a>
  è®­ç»ƒæ•°æ®çš„æ ¼å¼å¦‚ä¸‹:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  æµ· O
  é’“ O
  æ¯” O
  èµ› O
  åœ° O
  ç‚¹ O
  åœ¨ O
  å¦ B-LOC
  é—¨ I-LOC
  ä¸ O
  é‡‘ B-LOC
  é—¨ I-LOC
  ä¹‹ O
  é—´ O
  çš„ O
  æµ· O
  åŸŸ O
  ã€‚ O
</code></pre></div>    </div>

    <p>æ¯è¡Œå¾—ç¬¬ä¸€ä¸ªæ˜¯å­—ï¼Œç¬¬äºŒä¸ªæ˜¯å®ƒçš„æ ‡ç­¾ï¼Œä½¿ç”¨ç©ºæ ¼â€™ â€˜åˆ†éš”ï¼Œè¯·ä¸€å®šè¦ä½¿ç”¨ç©ºæ ¼ã€‚å¥ä¸å¥ä¹‹é—´ä½¿ç”¨ç©ºè¡Œåˆ’åˆ†ã€‚ç¨‹åºä¼šè‡ªåŠ¨è¯»å–ä½ çš„æ•°æ®ã€‚</p>
  </li>
  <li>
    <p>output_dirï¼š è®­ç»ƒæ¨¡å‹è¾“å‡ºçš„æ–‡ä»¶è·¯å¾„ï¼Œæ¨¡å‹çš„checkpointä»¥åŠä¸€äº›æ ‡ç­¾æ˜ å°„è¡¨éƒ½ä¼šå­˜å‚¨åœ¨è¿™é‡Œï¼Œè¿™ä¸ªè·¯å¾„åœ¨ä½œä¸ºæœåŠ¡çš„æ—¶å€™ï¼Œå¯ä»¥æŒ‡å®šä¸º-ner_model_dir</p>
  </li>
  <li>
    <p>init_checkpoint: ä¸‹è½½çš„è°·æ­ŒBERTæ¨¡å‹</p>
  </li>
  <li>
    <p>bert_config_file ï¼š è°·æ­ŒBERTæ¨¡å‹ä¸‹é¢çš„bert_config.json</p>
  </li>
  <li>
    <p>vocab_fileï¼š è°·æ­ŒBERTæ¨¡å‹ä¸‹é¢çš„vocab.txt</p>

    <p>è®­ç»ƒå®Œæˆåï¼Œä½ å¯ä»¥åœ¨ä½ æŒ‡å®šçš„output_dirä¸­æŸ¥çœ‹è®­ç»ƒç»“æœã€‚</p>
  </li>
</ul>

<h1 id="ä¸‰bert-base-serving-start-å°†å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡è¿›è¡ŒæœåŠ¡éƒ¨ç½²">ä¸‰ã€bert-base-serving-start å°†å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡è¿›è¡ŒæœåŠ¡éƒ¨ç½²</h1>

<p>å…ˆä½¿ç”¨-helpæŸ¥çœ‹ç›¸å…³å¸®åŠ©</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensorflow) root@e1fd7a8d1822:~/tian# bert-base-serving-start -help
usage: bert-base-serving-start [-h] -bert_model_dir BERT_MODEL_DIR -model_dir
                               MODEL_DIR [-model_pb_dir MODEL_PB_DIR]
                               [-tuned_model_dir TUNED_MODEL_DIR]
                               [-ckpt_name CKPT_NAME]
                               [-config_name CONFIG_NAME]
                               [-max_seq_len MAX_SEQ_LEN]
                               [-pooling_layer POOLING_LAYER [POOLING_LAYER ...]]
                               [-pooling_strategy {NONE,REDUCE_MAX,REDUCE_MEAN,REDUCE_MEAN_MAX,FIRST_TOKEN,LAST_TOKEN}]
                               [-mask_cls_sep] [-lstm_size LSTM_SIZE]
                               [-port PORT] [-port_out PORT_OUT]
                               [-http_port HTTP_PORT]
                               [-http_max_connect HTTP_MAX_CONNECT]
                               [-cors CORS] [-num_worker NUM_WORKER]
                               [-max_batch_size MAX_BATCH_SIZE]
                               [-priority_batch_size PRIORITY_BATCH_SIZE]
                               [-cpu] [-xla] [-fp16]
                               [-gpu_memory_fraction GPU_MEMORY_FRACTION]
                               [-device_map DEVICE_MAP [DEVICE_MAP ...]]
                               [-prefetch_size PREFETCH_SIZE] [-verbose]
                               [-mode MODE] [-version]
bert-base-serving-start: error: argument -h/--help: ignored explicit argument 'elp'
</code></pre></div></div>

<p>ä½œä¸ºå‘½åå®ä½“è¯†åˆ«ä»»åŠ¡çš„æœåŠ¡ï¼Œè¿™ä¸¤ä¸ªç›®å½•æ˜¯ä½ å¿…é¡»æŒ‡å®šçš„ï¼šner_model_dir, bert_model_dir
ç„¶åä½ å°±å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤å¯åŠ¨äº†ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-serving-start \
    -model_dir C:\workspace\python\BERT_Base\output\ner2 \
    -bert_model_dir F:\chinese_L-12_H-768_A-12
    -mode NER
</code></pre></div></div>

<ul>
  <li>bert_model_dir: è°·æ­ŒBERTæ¨¡å‹çš„è§£å‹è·¯å¾„,å¯ä»¥åœ¨è¿™é‡Œä¸‹è½½ https://github.com/google-research/bert</li>
  <li>model_dir: è®­ç»ƒå¥½çš„NERæ¨¡å‹æˆ–è€…æ–‡æœ¬åˆ†ç±»æ¨¡å‹çš„è·¯å¾„ï¼Œå¯¹äºä¸Šé¢çš„output_dir</li>
  <li>model_pd_dir: è¿è¡Œæ¨¡å‹ä¼˜åŒ–ä»£ç åï¼Œ ç»è¿‡æ¨¡å‹å‹ç¼©åçš„å­˜å‚¨è·¯å¾„ï¼Œä¾‹å¦‚è¿è¡Œä¸Šé¢çš„å‘½ä»¤åæ”¹è·¯å¾„ä¸‹ä¼šäº§ç”Ÿ ner_model.pb è¿™ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶</li>
  <li>mode:NER æˆ–è€…æ˜¯BERTè¿™ä¸¤ä¸ªæ¨¡å¼ï¼Œç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ˜¯NER,é‚£ä¹ˆå°±ä¼šå¯åŠ¨NERçš„æœåŠ¡ï¼Œå¦‚æœæ˜¯BERTï¼Œé‚£ä¹ˆå…·ä½“å‚æ•°å°†å’Œ[bert as service] é¡¹ç›®ä¸­å¾—ä¸€æ ·ã€‚</li>
</ul>

<h1 id="å››åœ¨æœ¬åœ°è¿æ¥æœåŠ¡ç«¯è¿›è¡Œå‘½åå®ä½“è¯†åˆ«çš„æµ‹è¯•">å››ã€åœ¨æœ¬åœ°è¿æ¥æœåŠ¡ç«¯è¿›è¡Œå‘½åå®ä½“è¯†åˆ«çš„æµ‹è¯•</h1>

<p>â€¦â€¦</p>

<h1 id="äº”è‡ªå·±è®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹">äº”ã€è‡ªå·±è®­ç»ƒå‘½åå®ä½“è¯†åˆ«æ¨¡å‹</h1>

<h2 id="1-ä¸‹è½½google-bert-é¢„è®­ç»ƒæ¨¡å‹">1. ä¸‹è½½Google BERT é¢„è®­ç»ƒæ¨¡å‹ï¼š</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip  
unzip chinese_L-12_H-768_A-12.zip
</code></pre></div></div>

<h2 id="2-è®­ç»ƒæ¨¡å‹">2. è®­ç»ƒæ¨¡å‹</h2>

<p>è®­ç»ƒä¹‹å‰å…ˆåœ¨é¡¹ç›®ç›®å½•ä¸­æ–°å»ºä¸€ä¸ªoutputæ–‡ä»¶å¤¹ï¼Œæ¨¡å‹çš„è¾“å‡ºï¼Œå’Œç»“æ„éƒ½ä¼šä¿å­˜åœ¨è¿™ä¸ªç›®å½•ä¸­<code class="language-plaintext highlighter-rouge">mkdir output</code></p>

<p>237ä¸Šè®­ç»ƒçš„å‘½ä»¤ï¼ˆGPUï¼‰</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-ner-train \
	-data_dir /root/tian/BERT-BiLSTM-CRF-NER/data/ne_WIPO_NER2 \
    -output_dir /root/tian/BERT-BiLSTM-CRF-NER/output/ne_WIPO_NER2 \
    -init_checkpoint /root/tian/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_model.ckpt \
    -bert_config_file /root/tian/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_config.json \
    -vocab_file /root/tian/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/vocab.txt \
    -save_summary_steps 20 \
    -batch_size 32 \
    -device_map 0
</code></pre></div></div>

<p>238ä¸Šè®­ç»ƒçš„å‘½ä»¤ï¼ˆCPUï¼‰</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bert-base-ner-train \
	-data_dir /root/tian/bert/BERT-BiLSTM-CRF-NER/data/ne_WIPO_NER \
    -output_dir /root/tian/bert/BERT-BiLSTM-CRF-NER/output/ne_WIPO_NER \
    -init_checkpoint /root/tian/bert/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_model.ckpt \
    -bert_config_file /root/tian/bert/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/bert_config.json \
    -vocab_file /root/tian/bert/BERT-BiLSTM-CRF-NER/chinese_L-12_H-768_A-12/vocab.txt \
    -save_summary_steps 20
</code></pre></div></div>

<h2 id="3-åœ¨çº¿é¢„æµ‹">3. åœ¨çº¿é¢„æµ‹</h2>

<p>å½“ä½ çš„æ¨¡å‹è®­ç»ƒå®Œåï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„è„šæœ¬åŠ è½½æ¨¡å‹ï¼Œè¿›è¡Œåœ¨çº¿é¢„æµ‹</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python3</span> <span class="n">terminal_predict_term</span><span class="p">.</span><span class="n">py</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WARNING:tensorflow:From /root/miniconda3/envs/tensorflow1.14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
{1: 'B', 2: 'E', 3: '[CLS]', 4: 'O', 5: 'M', 6: 'X', 7: 'S', 8: '[SEP]'}
input the test sentence:
ä¸€ç§é£èƒ½å‘ç”µæœºæ§åˆ¶ç®±åŸºåº§ç»„è£…é’»å­”è£…ç½®ï¼ŒåŒ…æ‹¬æ¿ä½“ï¼Œæ‰€è¿°æ¿ä½“ä¸Šè®¾æœ‰å‡é‡å­”ï¼Œæ‰€è¿°æ¿ä½“ä¸ºé•¿æ–¹å½¢ç»“æ„ï¼Œæ¿ä½“çŸ­è¾¹çš„ä¸¤ä¸ªè§’å¤„è®¾æœ‰ç¬¬ä¸€å»¶ä¼¸éƒ¨ï¼Œé•¿è¾¹çš„ä¸¤ä¸ªè§’å¤„è®¾æœ‰ç¬¬äºŒå»¶ä¼¸éƒ¨ï¼Œç¬¬ä¸€å»¶ä¼¸éƒ¨å’Œç¬¬äºŒå»¶ä¼¸éƒ¨çš„ä¸­å¿ƒè®¾æœ‰é’»å­”ï¼Œæ‰€è¿°ç¬¬ä¸€å»¶ä¼¸éƒ¨çš„åº•éƒ¨è®¾æœ‰åœ†åº§å›ºå®šå™¨ï¼Œåœ†åº§å›ºå®šå™¨çš„ä¸­éƒ¨è®¾æœ‰åœ†åº§æ§½ï¼Œæœ¬å®ç”¨æ–°å‹æ‰€è¿°çš„ä¸€ç§é£èƒ½å‘ç”µæœºæ§åˆ¶ç®±åŸºåº§ç»„è£…é’»å­”è£…ç½®ï¼Œè¯¥è£…ç½®é¦–å…ˆè§£å†³äº†å°ºå¯¸çš„é—®é¢˜ï¼Œèƒ½å¤Ÿä¿è¯åœ†åº§ä¸Šçš„å­”ä¸æ§åˆ¶ç®±çš„å­”ä½ç½®ä¸€è‡´ï¼Œä¿è¯æ§åˆ¶ç®±çš„å®‰è£…ï¼Œå¦ä¸€æ–¹é¢ï¼Œä¿è¯è¿æ¥æ¿ä¸è¢«æŠ˜å¼¯ï¼Œä»¥è¿æ¥æ¿ä¸Šçš„åœ†åº§æ¥å®šä½ç«¯éƒ¨ä¾§é¢çš„åœ†åº§ï¼Œæ–¹ä¾¿ç®€æ´ï¼Œä¸æ˜“å‡ºé”™ã€‚
2020-07-16 08:16:08.059521: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-07-16 08:16:08.103926: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'E', 'B', 'E', 'B', 'E', 'B', 'E', 'O', 'O', 'O', 'B', 'E', 'O', 'O', 'O', 'B', 'E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'E', 'O', 'B', 'M', 'E', 'B', 'E', 'O', 'B', 'E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'E', 'O', 'O', 'B', 'E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'M', 'E', 'O', 'O', 'O', 'B', 'M', 'E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'M', 'M', 'E', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'E', 'B', 'E', 'B', 'E', 'B', 'E', 'O', 'O', 'B', 'E', 'O', 'O', 'B', 'E', 'O', 'B', 'E', 'O', 'B', 'E', 'O', 'O', 'O', 'B', 'E', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'M', 'E', 'O', 'O', 'B', 'E', 'B', 'E', 'O', 'B', 'E', 'B', 'M', 'E', 'O', 'B', 'E', 'O', 'O']]
LOC
PER
ORG
time used: 1.304257 sec
</code></pre></div></div>

<h1 id="links">Links:</h1>

<ol>
  <li>ã€æ–°å…¨ã€‘2019 NLP(è‡ªç„¶è¯­è¨€å¤„ç†)ä¹‹Bertè¯¾ç¨‹https://www.bilibili.com/video/av76791626?p=29</li>
  <li>åŸºäºBERTé¢„è®­ç»ƒçš„ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«TensorFlowå®ç°åšå®¢ï¼Œä¸»è¦å‚è€ƒçš„æ˜¯è¿™ç¯‡åšå®¢ï¼Œè¿˜æœ‰GitHubåº“ https://blog.csdn.net/macanv/article/details/85684284    https://github.com/macanv/BERT-BiLSTM-CRF-NER      ï¼ˆæ ¹æ®è¿™ç¯‡åšå®¢é‡Œè®­ç»ƒå®Œäº†æ¨¡å‹åå°±å¯ä»¥è¿›è¡Œé¢„æµ‹äº†ã€‚python3 terminal_predict.pyï¼‰</li>
  <li>Bert-BiLSTM-CRF-pytorch ä¸€ä¸ªGitHubåº“ï¼Œçœ‹èµ·æ¥ä¹Ÿä¸é”™ https://github.com/chenxiaoyouyou/Bert-BiLSTM-CRF-pytorch</li>
</ol>
:ET