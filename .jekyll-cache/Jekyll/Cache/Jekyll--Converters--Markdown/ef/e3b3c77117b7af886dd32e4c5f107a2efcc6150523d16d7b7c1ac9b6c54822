I")Œ<h3 id="1-pytorchä¸­çš„embeddingè¯å‘é‡çš„ä½¿ç”¨">1. <a href="https://blog.csdn.net/david0611/article/details/81090371">pytorchä¸­çš„embeddingè¯å‘é‡çš„ä½¿ç”¨</a></h3>
<h5 id="embedding">Embedding</h5>
<p>è¯åµŒå…¥åœ¨ pytorch ä¸­éå¸¸ç®€å•ï¼Œåªéœ€è¦è°ƒç”¨ torch.nn.Embedding(m, n) å°±å¯ä»¥äº†ï¼Œm è¡¨ç¤ºå•è¯çš„æ€»æ•°ç›®ï¼Œn è¡¨ç¤ºè¯åµŒå…¥çš„ç»´åº¦ï¼Œå…¶å®è¯åµŒå…¥å°±ç›¸å½“äºæ˜¯ä¸€ä¸ªå¤§çŸ©é˜µï¼ŒçŸ©é˜µçš„æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªå•è¯ã€‚</p>

<h5 id="emdeddingåˆå§‹åŒ–">emdeddingåˆå§‹åŒ–</h5>
<p>é»˜è®¤æ˜¯éšæœºåˆå§‹åŒ–çš„</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="c1"># å®šä¹‰è¯åµŒå…¥
</span><span class="n">embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># 2 ä¸ªå•è¯ï¼Œç»´åº¦ 5
# å¾—åˆ°è¯åµŒå…¥çŸ©é˜µ,å¼€å§‹æ˜¯éšæœºåˆå§‹åŒ–çš„
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">embeds</span><span class="p">.</span><span class="n">weight</span>
<span class="c1"># è¾“å‡ºç»“æœï¼š
</span><span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span>
<span class="o">-</span><span class="mf">0.8923</span> <span class="o">-</span><span class="mf">0.0583</span> <span class="o">-</span><span class="mf">0.1955</span> <span class="o">-</span><span class="mf">0.9656</span>  <span class="mf">0.4224</span>
 <span class="mf">0.2673</span> <span class="o">-</span><span class="mf">0.4212</span> <span class="o">-</span><span class="mf">0.5107</span> <span class="o">-</span><span class="mf">1.5727</span> <span class="o">-</span><span class="mf">0.1232</span>
<span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">2</span><span class="n">x5</span><span class="p">]</span>
</code></pre></div></div>
<p>å¦‚æœä»ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„è¯å‘é‡ï¼Œåˆ™é‡‡ç”¨</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pretrained_weight</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">pretrained_weight</span><span class="p">)</span>  <span class="c1"># å·²æœ‰è¯å‘é‡çš„numpy
</span><span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">pretrained_weight</span><span class="p">))</span>
</code></pre></div></div>

<h5 id="embedçš„è¯»å–">embedçš„è¯»å–</h5>
<p>è¯»å–ä¸€ä¸ªå‘é‡ã€‚ 
æ³¨æ„å‚æ•°åªèƒ½æ˜¯LongTensorå‹çš„</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># è®¿é—®ç¬¬ 50 ä¸ªè¯çš„è¯å‘é‡
</span><span class="n">embeds</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">embeds</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">50</span><span class="p">])))</span>
<span class="c1"># è¾“å‡ºï¼š
</span><span class="n">Variable</span> <span class="n">containing</span><span class="p">:</span>
 <span class="mf">0.6353</span>  <span class="mf">1.0526</span>  <span class="mf">1.2452</span> <span class="o">-</span><span class="mf">1.8745</span> <span class="o">-</span><span class="mf">0.1069</span>  <span class="mf">0.1979</span>  <span class="mf">0.4298</span> <span class="o">-</span><span class="mf">0.3652</span> <span class="o">-</span><span class="mf">0.7078</span>  <span class="mf">0.2642</span>
<span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">1</span><span class="n">x10</span><span class="p">]</span>
</code></pre></div></div>
<p>è¯»å–å¤šä¸ªå‘é‡ã€‚ 
è¾“å…¥ä¸ºä¸¤ä¸ªç»´åº¦(batchçš„å¤§å°ï¼Œæ¯ä¸ªbatchçš„å•è¯ä¸ªæ•°)ï¼Œè¾“å‡ºåˆ™åœ¨ä¸¤ä¸ªç»´åº¦ä¸ŠåŠ ä¸Šè¯å‘é‡çš„å¤§å°ã€‚</p>

<ul>
  <li>Input: LongTensor (N, W), N = mini-batch, W = number of indices to extract per mini-batch</li>
  <li>Output: (N, W, embedding_dim)
è§ä»£ç 
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># an Embedding module containing 10 tensors of size 3
</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># æ¯æ‰¹å–ä¸¤ç»„ï¼Œæ¯ç»„å››ä¸ªå•è¯
</span><span class="nb">input</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">]]))</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># è¾“å‡º2*4*3
</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>    </div>
    <p>è¾“å‡ºä¸ºï¼š</p>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">Variable</span> <span class="n">containing</span><span class="p">:</span>
 <span class="o">-</span><span class="mf">1.2603</span>  <span class="mf">0.4337</span>  <span class="mf">0.4181</span>
<span class="mf">0.4458</span> <span class="o">-</span><span class="mf">0.1987</span>  <span class="mf">0.4971</span>
 <span class="o">-</span><span class="mf">0.5783</span>  <span class="mf">1.3640</span>  <span class="mf">0.7588</span>
<span class="mf">0.4956</span> <span class="o">-</span><span class="mf">0.2379</span> <span class="o">-</span><span class="mf">0.7678</span>
 <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x3</span><span class="p">],</span> <span class="n">Variable</span> <span class="n">containing</span><span class="p">:</span>
 <span class="o">-</span><span class="mf">0.5783</span>  <span class="mf">1.3640</span>  <span class="mf">0.7588</span>
 <span class="o">-</span><span class="mf">0.5313</span> <span class="o">-</span><span class="mf">0.3886</span> <span class="o">-</span><span class="mf">0.6110</span>
<span class="mf">0.4458</span> <span class="o">-</span><span class="mf">0.1987</span>  <span class="mf">0.4971</span>
 <span class="o">-</span><span class="mf">1.3768</span>  <span class="mf">1.7323</span>  <span class="mf">0.4816</span>
 <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x3</span><span class="p">])</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="2-å…³äºpytorchä¸­çš„gru">2. <a href="https://www.cnblogs.com/duye/p/10590146.html">å…³äºpytorchä¸­çš„GRU</a></h3>
<p>å–è¯å‘é‡ï¼Œæ”¾è¿›GRUã€‚</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gru</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span><span class="n">hidden_size</span><span class="p">,</span><span class="n">n_layers</span><span class="p">)</span>
<span class="c1"># è¿™é‡Œçš„input_sizeå°±æ˜¯è¯å‘é‡çš„ç»´åº¦ï¼Œhidden_sizeå°±æ˜¯RNNéšè—å±‚çš„ç»´åº¦ï¼Œè¿™ä¸¤ä¸ªä¸€èˆ¬ç›¸åŒå°±å¯ä»¥
# n_layersæ˜¯GRUçš„å±‚æ•°
</span></code></pre></div></div>
<p>å¯è§ï¼Œå¹¶ä¸éœ€è¦æŒ‡å®šæ—¶é—´æ­¥æ•°ï¼Œä¹Ÿå³seq_lenï¼Œè¿™æ˜¯å› ä¸ºï¼ŒGRUå’ŒLSTMéƒ½å®ç°äº†è‡ªèº«çš„è¿­ä»£ã€‚</p>

<h3 id="3-embedded--selfembeddinginputview1-1--1">3. <a href="https://blog.csdn.net/jiangpeng59/article/details/84859640">embedded = self.embedding(input).view(1, 1, -1)</a></h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">).</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># RNNçš„è¾“å…¥å¤§å°éƒ½æ˜¯(1,1,hidden_size)ï¼Œå³batch=1,seq_len=1,hidden_size=embed_size
</span></code></pre></div></div>
<p>RNNçš„è¾“å…¥å¤§å°éƒ½æ˜¯(1,1,hidden_size)ï¼Œå³batch=1,seq_len=1,hidden_size=embed_size</p>

<h3 id="4-nnsoftmaxä¸nnlogsoftmax">4. <a href="https://blog.csdn.net/geter_CS/article/details/82878083">nn.Softmax()ä¸nn.LogSoftmax()</a></h3>
<p>nn.Softmax()è®¡ç®—å‡ºæ¥çš„å€¼ï¼Œå…¶å’Œä¸º1ï¼Œä¹Ÿå°±æ˜¯è¾“å‡ºçš„æ˜¯æ¦‚ç‡åˆ†å¸ƒ<br />
è€Œlogsofmaxè¾“å‡ºçš„æ˜¯å°äº0çš„æ•°</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">layer1</span><span class="o">=</span><span class="n">nn</span><span class="p">.</span><span class="n">Softmax</span><span class="p">()</span>
<span class="n">layer2</span><span class="o">=</span><span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">()</span>
 
<span class="nb">input</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">input</span><span class="o">=</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
 
<span class="n">output1</span><span class="o">=</span><span class="n">layer1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output2</span><span class="o">=</span><span class="n">layer2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'output1:'</span><span class="p">,</span><span class="n">output1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'output2:'</span><span class="p">,</span><span class="n">output2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">output1</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.2689</span><span class="p">,</span> <span class="mf">0.7311</span><span class="p">])</span>
<span class="n">output2</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.3133</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3133</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="5-pytorchä¹‹nnreluä¸freluçš„åŒºåˆ«">5. <a href="https://blog.csdn.net/u011501388/article/details/86602275">PyTorchä¹‹nn.ReLUä¸F.ReLUçš„åŒºåˆ«</a></h3>
<p>nn.ReLUä½œä¸ºä¸€ä¸ªå±‚ç»“æ„ï¼Œå¿…é¡»æ·»åŠ åˆ°nn.Moduleå®¹å™¨ä¸­æ‰èƒ½ä½¿ç”¨ï¼Œè€ŒF.ReLUåˆ™ä½œä¸ºä¸€ä¸ªå‡½æ•°è°ƒç”¨ï¼Œçœ‹ä¸Šå»ä½œä¸ºä¸€ä¸ªå‡½æ•°è°ƒç”¨æ›´æ–¹ä¾¿æ›´ç®€æ´ã€‚</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
 
<span class="k">class</span> <span class="nc">AlexNet_1</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">n</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
         <span class="p">)</span>
 
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
 
<span class="k">class</span> <span class="nc">AlexNet_2</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">n</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
         <span class="p">)</span>
 
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="6-reluå‡½æ•°ä½œç”¨">6. <a href="https://www.zhihu.com/question/29021768">Reluå‡½æ•°ä½œç”¨</a></h3>
<p>1.ä¸ºä»€ä¹ˆå¼•å…¥éçº¿æ€§æ¿€åŠ±å‡½æ•°ï¼Ÿ</p>

<p>å¦‚æœä¸é€‚ç”¨æ¿€åŠ±å‡½æ•°ï¼Œé‚£ä¹ˆåœ¨è¿™ç§æƒ…å†µä¸‹æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½æ˜¯ä¸Šå±‚è¾“å…¥çš„çº¿æ€§å‡½æ•°ï¼Œå¾ˆå®¹æ˜“éªŒè¯ï¼Œæ— è®ºä½ ç¥ç»ç½‘ç»œæœ‰å¤šå°‘å±‚ï¼Œè¾“å‡ºéƒ½æ˜¯è¾“å…¥çš„çº¿æ€§ç»„åˆï¼Œä¸æ²¡æœ‰éšè—å±‚æ•ˆæœç›¸å½“ï¼Œè¿™ç§æƒ…å†µå°±æ˜¯æœ€åŸå§‹çš„æ„ŸçŸ¥æœºï¼ˆperceptronï¼‰äº†</p>

<p>æ­£å› ä¸ºä¸Šé¢çš„åŸå› ï¼Œæˆ‘ä»¬å†³å®šå¼•å…¥éçº¿æ€§å‡½æ•°ä½œä¸ºæ¿€åŠ±å‡½æ•°ï¼Œè¿™æ ·æ·±å±‚ç¥ç»ç½‘ç»œå°±æœ‰æ„ä¹‰äº†ï¼Œä¸å†æ˜¯è¾“å…¥çš„çº¿æ€§ç»„åˆï¼Œå¯ä»¥é€¼è¿‘ä»»æ„å‡½æ•°ï¼Œæœ€æ—©çš„æƒ³æ³•æ˜¯ç”¨sigmoidå‡½æ•°æˆ–è€…tanhå‡½æ•°ï¼Œè¾“å‡ºæœ‰ç•Œï¼Œå¾ˆå®¹æ˜“å……å½“ä¸‹ä¸€å±‚çš„è¾“å…¥</p>

<p>2.ä¸ºä»€ä¹ˆå¼•å…¥Relu?</p>

<p>ç¬¬ä¸€ï¼Œé‡‡ç”¨sigmoidç­‰å‡½æ•°ï¼Œç®—æ¿€æ´»å‡½æ•°æ—¶å€™ï¼ˆæŒ‡æ•°è¿ç®—ï¼‰ï¼Œè®¡ç®—é‡å¤§ï¼Œåå‘ä¼ æ’­æ±‚è¯¯å·®æ¢¯åº¦æ—¶ï¼Œæ±‚å¯¼æ¶‰åŠé™¤æ³•ï¼Œè®¡ç®—é‡ç›¸å½“å¤§ï¼Œè€Œé‡‡ç”¨Reluæ¿€æ´»å‡½æ•°ï¼Œæ•´ä¸ªè¿‡ç¨‹çš„è®¡ç®—é‡èŠ‚çœå¾ˆå¤š</p>

<p>ç¬¬äºŒï¼Œå¯¹äºæ·±å±‚ç½‘ç»œï¼Œsigmoidå‡½æ•°åå‘ä¼ æ’­æ—¶ï¼Œå¾ˆå®¹æ˜“å°±å‡ºç°æ¢¯åº¦æ¶ˆå¤±çš„æƒ…å†µï¼ˆåœ¨sigmoidå‡½æ•°æ¥è¿‘é¥±å’ŒåŒºæ—¶ï¼Œå˜æ¢å¤ªç¼“æ…¢ï¼Œå¯¼æ•°è¶‹äº0ï¼Œè¿™ç§æƒ…å†µä¼šé€ æˆä¿¡æ¯ä¸¢å¤±ï¼‰ï¼Œä»è€Œæ— æ³•å®Œæˆæ·±å±‚ç½‘ç»œçš„è®­ç»ƒ</p>

<p>ç¬¬ä¸‰ï¼ŒReluä¼šä½¿ä¸€éƒ¨åˆ†ç¥ç»å…ƒçš„è¾“å‡ºä¸º0ï¼Œè¿™æ ·å°±é€ æˆäº†ç½‘ç»œçš„ç¨€ç–æ€§ï¼Œå¹¶ä¸”å‡å°‘äº†å‚æ•°çš„ç›¸äº’ä¾å­˜å…³ç³»ï¼Œç¼“è§£äº†è¿‡æ‹Ÿåˆé—®é¢˜çš„å‘ç”Ÿ</p>

<p>å½“ç„¶ï¼Œç°åœ¨ä¹Ÿæœ‰ä¸€äº›å¯¹reluçš„æ”¹è¿›ï¼Œæ¯”å¦‚ï¼Œpreluï¼Œrandom reluç­‰ï¼Œåœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šä¼šæœ‰ä¸€äº›è®­ç»ƒé€Ÿåº¦ä¸Šæˆ–è€…å‡†ç¡®ç‡ä¸Šçš„æ”¹è¿›</p>

<p>å¤šåŠ ä¸€å¥ï¼Œç°åœ¨ä¸»æµçš„åšæ³•ï¼Œä¼šå¤šåšä¸€æ­¥batch normalizationï¼Œå°½å¯èƒ½ä¿è¯æ¯ä¸€å±‚ç½‘ç»œçš„è¾“å…¥å…·æœ‰ç›¸åŒçš„åˆ†å¸ƒ</p>

<p>ä¸€è¨€ä»¥è”½ä¹‹ï¼Œå…¶å®ï¼Œreluå‡½æ•°çš„ä½œç”¨å°±æ˜¯å¢åŠ äº†ç¥ç»ç½‘ç»œå„å±‚ä¹‹é—´çš„éçº¿æ€§å…³ç³»ï¼Œå¦åˆ™ï¼Œå¦‚æœæ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œå±‚ä¸å±‚ä¹‹é—´æ˜¯ç®€å•çš„çº¿æ€§å…³ç³»ï¼Œæ¯å±‚éƒ½ç›¸å½“äºçŸ©é˜µç›¸ä¹˜ï¼Œè¿™æ ·æ€ä¹ˆèƒ½å¤Ÿå®Œæˆæˆ‘ä»¬éœ€è¦ç¥ç»ç½‘ç»œå®Œæˆçš„å¤æ‚ä»»åŠ¡ï¼Œ</p>

<p>æˆ‘ä»¬åˆ©ç”¨ç¥ç»ç½‘ç»œå»è§£å†³å›¾åƒåˆ†å‰²ï¼Œè¾¹ç•Œæ¢æµ‹ï¼Œè¶…åˆ†è¾¨ç­‰é—®é¢˜æ—¶å€™ï¼Œæˆ‘ä»¬çš„è¾“å…¥ï¼ˆå‡è®¾ä¸ºxï¼‰ï¼Œä¸æœŸæœ›çš„è¾“å‡ºï¼ˆå‡è®¾ä¸ºyï¼‰ä¹‹é—´çš„å…³ç³»ç©¶ç«Ÿæ˜¯ä»€ä¹ˆï¼Ÿä¹Ÿå°±æ˜¯y=f(x)ä¸­ï¼Œfæ˜¯ä»€ä¹ˆï¼Œæˆ‘ä»¬ä¹Ÿä¸æ¸…æ¥šï¼Œä½†æ˜¯æˆ‘ä»¬å¯¹ä¸€ç‚¹å¾ˆç¡®ä¿¡ï¼Œé‚£å°±æ˜¯fä¸æ˜¯ä¸€ä¸ªç®€å•çš„çº¿æ€§å‡½æ•°ï¼Œåº”è¯¥æ˜¯ä¸€ä¸ªæŠ½è±¡çš„å¤æ‚çš„å…³ç³»ï¼Œé‚£ä¹ˆåˆ©ç”¨ç¥ç»ç½‘ç»œå°±æ˜¯å»å­¦ä¹ è¿™ä¸ªå…³ç³»ï¼Œå­˜æ”¾åœ¨modelä¸­ï¼Œåˆ©ç”¨å¾—åˆ°çš„modelå»æ¨æµ‹è®­ç»ƒé›†ä¹‹å¤–çš„æ•°æ®ï¼Œå¾—åˆ°æœŸæœ›çš„ç»“æœ</p>

<h3 id="7-pytorchçš„torchcat">7. <a href="https://blog.csdn.net/qq_39709535/article/details/80803003">PyTorchçš„torch.cat</a></h3>
<p>torch.catæ˜¯å°†ä¸¤ä¸ªå¼ é‡ï¼ˆtensorï¼‰æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œcatæ˜¯concatnateçš„æ„æ€ï¼Œå³æ‹¼æ¥ï¼Œè”ç³»åœ¨ä¸€èµ·ã€‚
ä½¿ç”¨torch.cat((A,B),dim)æ—¶ï¼Œé™¤æ‹¼æ¥ç»´æ•°dimæ•°å€¼å¯ä¸åŒå¤–å…¶ä½™ç»´æ•°æ•°å€¼éœ€ç›¸åŒï¼Œæ–¹èƒ½å¯¹é½ã€‚</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="c1">#2x3çš„å¼ é‡ï¼ˆçŸ©é˜µï¼‰                                     
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">B</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="c1">#4x3çš„å¼ é‡ï¼ˆçŸ©é˜µï¼‰                                    
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">B</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">C</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">),</span><span class="mi">0</span><span class="p">)</span><span class="c1">#æŒ‰ç»´æ•°0ï¼ˆè¡Œï¼‰æ‹¼æ¥
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">C</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">C</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="c1">#2x4çš„å¼ é‡ï¼ˆçŸ©é˜µï¼‰
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">C</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">A</span><span class="p">,</span><span class="n">D</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span><span class="c1">#æŒ‰ç»´æ•°1ï¼ˆåˆ—ï¼‰æ‹¼æ¥
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">C</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">C</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="8-pytorchå­¦ä¹ -ä¸­-torchsqueeze-å’Œtorchunsqueezeçš„ç”¨æ³•">8. <a href="https://blog.csdn.net/xiexu911/article/details/80820028">pytorchå­¦ä¹  ä¸­ torch.squeeze() å’Œtorch.unsqueeze()çš„ç”¨æ³•</a></h3>
<p>squeezeçš„ç”¨æ³•ä¸»è¦å°±æ˜¯å¯¹æ•°æ®çš„ç»´åº¦è¿›è¡Œå‹ç¼©æˆ–è€…è§£å‹ã€‚</p>

<p>å…ˆçœ‹<strong>torch.squeeze()</strong> è¿™ä¸ªå‡½æ•°ä¸»è¦å¯¹æ•°æ®çš„ç»´åº¦è¿›è¡Œå‹ç¼©ï¼Œå»æ‰ç»´æ•°ä¸º1çš„çš„ç»´åº¦ï¼Œæ¯”å¦‚æ˜¯ä¸€è¡Œæˆ–è€…ä¸€åˆ—è¿™ç§ï¼Œä¸€ä¸ªä¸€è¡Œä¸‰åˆ—ï¼ˆ1,3ï¼‰çš„æ•°å»æ‰ç¬¬ä¸€ä¸ªç»´æ•°ä¸ºä¸€çš„ç»´åº¦ä¹‹åå°±å˜æˆï¼ˆ3ï¼‰è¡Œã€‚squeeze(a)å°±æ˜¯å°†aä¸­æ‰€æœ‰ä¸º1çš„ç»´åº¦åˆ æ‰ã€‚ä¸ä¸º1çš„ç»´åº¦æ²¡æœ‰å½±å“ã€‚a.squeeze(N) å°±æ˜¯å»æ‰aä¸­æŒ‡å®šçš„ç»´æ•°ä¸ºä¸€çš„ç»´åº¦ã€‚è¿˜æœ‰ä¸€ç§å½¢å¼å°±æ˜¯b=torch.squeeze(aï¼ŒN) aä¸­å»æ‰æŒ‡å®šçš„å®šçš„ç»´æ•°ä¸ºä¸€çš„ç»´åº¦ã€‚</p>

<p>å†çœ‹<strong>torch.unsqueeze()</strong> è¿™ä¸ªå‡½æ•°ä¸»è¦æ˜¯å¯¹æ•°æ®ç»´åº¦è¿›è¡Œæ‰©å……ã€‚ç»™æŒ‡å®šä½ç½®åŠ ä¸Šç»´æ•°ä¸ºä¸€çš„ç»´åº¦ï¼Œæ¯”å¦‚åŸæœ¬æœ‰ä¸ªä¸‰è¡Œçš„æ•°æ®ï¼ˆ3ï¼‰ï¼Œåœ¨0çš„ä½ç½®åŠ äº†ä¸€ç»´å°±å˜æˆä¸€è¡Œä¸‰åˆ—ï¼ˆ1,3ï¼‰ã€‚a.squeeze(N) å°±æ˜¯åœ¨aä¸­æŒ‡å®šä½ç½®NåŠ ä¸Šä¸€ä¸ªç»´æ•°ä¸º1çš„ç»´åº¦ã€‚è¿˜æœ‰ä¸€ç§å½¢å¼å°±æ˜¯b=torch.squeeze(aï¼ŒN) aå°±æ˜¯åœ¨aä¸­æŒ‡å®šä½ç½®NåŠ ä¸Šä¸€ä¸ªç»´æ•°ä¸º1çš„ç»´åº¦</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">.</span><span class="n">shape</span>

<span class="p">(</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0910</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1256</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5418</span><span class="p">]]),</span> <span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.0910</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1256</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5418</span><span class="p">]]])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.7645</span><span class="p">,</span>  <span class="mf">0.7322</span><span class="p">,</span>  <span class="mf">0.9287</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0910</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1256</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5418</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="9-ä¸€ç¯‡æ–‡ç« ææ‡‚pythonä¸­çš„é¢å‘å¯¹è±¡ç¼–ç¨‹">9. <a href="http://yangcongchufang.com/%E9%AB%98%E7%BA%A7python%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/python-object-class.html">ä¸€ç¯‡æ–‡ç« ææ‡‚Pythonä¸­çš„é¢å‘å¯¹è±¡ç¼–ç¨‹</a></h3>

<h3 id="10-æœåŠ¡å™¨è®­ç»ƒç¥ç»ç½‘ç»œå®¹æ˜“ä¸­æ–­ä¸­æ–­åéœ€è¦é‡æ–°è®­ç»ƒçš„è§£å†³åŠæ³•">10. æœåŠ¡å™¨è®­ç»ƒç¥ç»ç½‘ç»œå®¹æ˜“ä¸­æ–­ï¼Œä¸­æ–­åéœ€è¦é‡æ–°è®­ç»ƒçš„è§£å†³åŠæ³•</h3>
<p>ä¸€ã€å¼€å¯ä¸€ä¸ªæ–°çª—å£ï¼šscreen -S name<br />
äºŒã€å¯ä»¥å…³é—­è¿è¡Œçª—å£<br />
ä¸‰ã€screen -lsï¼šæŸ¥çœ‹å½“å‰æ‰“å¼€çš„çª—å£ï¼Œè¾“å…¥screen -r IDï¼Œå°±èƒ½è¿›å…¥åˆ°ç›¸åº”çš„screen  <br />
å››ã€å½“ç»“æŸç¨‹åºä»¥åï¼Œå¯ä»¥è¾“å…¥exitï¼Œæˆ–è€…screen -S screenID -X quitå…³é—­çª—å£</p>
:ET